{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Aympk-qwGu"
      },
      "source": [
        "# Preliminaries: model definition and utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFhWBUzvqmZF",
        "outputId": "5d1eeb38-3681-45e4-b732-2e5281fa39df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYllTn0F2iDg"
      },
      "source": [
        "# Neural Network definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plcXrgr8q_dR"
      },
      "source": [
        "WideResNet from following [repo](https://github.com/xternalz/WideResNet-pytorch/blob/master/wideresnet.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP2NJY4BrEH8"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                                                                padding=0, bias=False) or None\n",
        "    def forward(self, x):\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(self.bn1(x))\n",
        "        else:\n",
        "            out = self.relu1(self.bn1(x))\n",
        "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        out = self.conv2(out)\n",
        "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
        "\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "        super(NetworkBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "        layers = []\n",
        "        for i in range(int(nb_layers)):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0, hidden_dim = 50):\n",
        "        super(WideResNet, self).__init__()\n",
        "        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
        "        assert ((depth - 4) % 6 == 0)\n",
        "        n = (depth - 4) / 6\n",
        "        block = BasicBlock\n",
        "        # 1st conv before any network block\n",
        "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
        "        # 2nd block\n",
        "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
        "        # 3rd block\n",
        "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
        "        # global average pooling and classifier\n",
        "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(nChannels[3], hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "        self.nChannels = nChannels[3]\n",
        "        self.softmax = nn.Softmax()\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.nChannels)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.softmax(out)\n",
        "        return out\n",
        "    def repr(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.nChannels)\n",
        "        out = self.fc(out)\n",
        "        return out    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeFb2p2TzjbF"
      },
      "outputs": [],
      "source": [
        "# simple conv network\n",
        "# (argument 2 of the first nn.Conv2d, and argument 1 of the second nn.Conv2d â€“ they need to be the same number)\n",
        "class NetSimple(nn.Module):\n",
        "    def __init__(self, num_classes, width1 = 6, width2 = 16,ff_units1 = 120, ff_units2 = 84):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, width1, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(width1, width2, 5)\n",
        "        self.fc1 = nn.Linear(width2 * 5 * 5, ff_units1)\n",
        "        self.fc2 = nn.Linear(ff_units1, ff_units2)\n",
        "        self.fc3 = nn.Linear(ff_units2, num_classes)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "    def repr(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_net_rej(nn.Module):\n",
        "    '''\n",
        "    Linear Classifier to be used for the L_CE loss\n",
        "    '''\n",
        "    def __init__(self, input_dim, out_dim):\n",
        "        super(Linear_net_rej, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc = nn.Linear(input_dim, out_dim+1)\n",
        "        self.fc_rej = nn.Linear(input_dim, 1)\n",
        "        torch.nn.init.ones_(self.fc.weight)\n",
        "        torch.nn.init.ones_(self.fc_rej.weight)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "        rej = self.fc_rej(x)\n",
        "        #out = torch.cat([out,rej],1)\n",
        "        out = self.softmax(out)\n",
        "        return out\n",
        "\n",
        "class Linear_net(nn.Module):\n",
        "    '''\n",
        "    Linear multiclass classifier with unit init\n",
        "    '''\n",
        "    def __init__(self, input_dim, out_dim):\n",
        "        super(Linear_net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(input_dim, out_dim)\n",
        "        torch.nn.init.normal_(self.fc1.weight)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "w7cE6V6QoMwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple conv network\n",
        "# (argument 2 of the first nn.Conv2d, and argument 1 of the second nn.Conv2d â€“ they need to be the same number)\n",
        "class NetComplex(nn.Module):\n",
        "    def __init__(self, num_classes, width1 = 6, width2 = 16,ff_units1 = 120, ff_units2 = 84):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, width1, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(width1, width2, 5)\n",
        "        self.conv3 = nn.Conv2d(width2, width2, 5)\n",
        "        self.fc1 = nn.Linear(width2 * 3 * 3, ff_units1)\n",
        "        self.fc2 = nn.Linear(ff_units1, ff_units2)\n",
        "        self.fc3 = nn.Linear(ff_units2, num_classes)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        to_print_size = False\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        if to_print_size:\n",
        "            print(x.size())\n",
        "        x = F.relu(self.conv2(x))\n",
        "        if to_print_size:\n",
        "            print(x.size())\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        if to_print_size:\n",
        "            print(x.size())\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        if to_print_size:\n",
        "            print(x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "jex4IogFu-c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ll6QD_IrQeD"
      },
      "source": [
        "# Metrics and utilities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reject_CrossEntropyLoss(outputs, m, labels, m2, n_classes):\n",
        "    '''\n",
        "    The L_{CE} loss implementation for CIFAR\n",
        "    ----\n",
        "    outputs: network outputs\n",
        "    m: cost of deferring to expert cost of classifier predicting (I_{m =y})\n",
        "    labels: target\n",
        "    m2:  cost of classifier predicting (alpha* I_{m\\neq y} + I_{m =y})\n",
        "    n_classes: number of classes\n",
        "    '''\n",
        "    batch_size = outputs.size()[0]  # batch_size\n",
        "    rc = [n_classes] * batch_size\n",
        "    outputs = -m * torch.log2(outputs[range(batch_size), rc]) - m2 * torch.log2(\n",
        "        outputs[range(batch_size), labels])  \n",
        "    return torch.sum(outputs) / batch_size\n",
        "\n",
        "def my_CrossEntropyLoss(outputs, labels):\n",
        "    # Regular Cross entropy loss\n",
        "    batch_size = outputs.size()[0]  # batch_size\n",
        "    outputs = - torch.log2(outputs[range(batch_size), labels])  # regular CE\n",
        "    return torch.sum(outputs) / batch_size\n"
      ],
      "metadata": {
        "id": "nKY9Bxfx2Xy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m93DvFTXrRwt"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def metrics_print(net, expert_fn, n_classes, loader):\n",
        "    '''\n",
        "    Computes metrics for deferal\n",
        "    -----\n",
        "    Arguments:\n",
        "    net: model\n",
        "    expert_fn: expert model\n",
        "    n_classes: number of classes\n",
        "    loader: data loader\n",
        "    '''\n",
        "    correct = 0\n",
        "    correct_sys = 0\n",
        "    exp = 0\n",
        "    exp_total = 0\n",
        "    total = 0\n",
        "    real_total = 0\n",
        "    alone_correct = 0\n",
        "    correct_pred = {classname: 0 for classname in cifar_classes}\n",
        "    total_pred = {classname: 0 for classname in cifar_classes}\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels, _, _ ,_ = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            batch_size = outputs.size()[0]  # batch_size\n",
        "            exp_prediction = expert_fn(images, labels)\n",
        "            for i in range(0, batch_size):\n",
        "                r = (predicted[i].item() == n_classes)\n",
        "                prediction = predicted[i]\n",
        "                final_pred = 0\n",
        "                if predicted[i] == n_classes:\n",
        "                    max_idx = 0\n",
        "                    # get second max\n",
        "                    for j in range(0, n_classes):\n",
        "                        if outputs.data[i][j] >= outputs.data[i][max_idx]:\n",
        "                            max_idx = j\n",
        "                    prediction = max_idx\n",
        "                else:\n",
        "                    prediction = predicted[i]\n",
        "                alone_correct += (prediction == labels[i]).item()\n",
        "                if r == 0:\n",
        "                    total += 1\n",
        "                    final_pred = predicted[i]\n",
        "                    correct += (predicted[i] == labels[i]).item()\n",
        "                    correct_sys += (predicted[i] == labels[i]).item()\n",
        "                if r == 1:\n",
        "                    final_pred = exp_prediction[i]\n",
        "                    exp += (exp_prediction[i] == labels[i].item())\n",
        "                    correct_sys += (exp_prediction[i] == labels[i].item())\n",
        "                    exp_total += 1\n",
        "                real_total += 1\n",
        "                if labels[i].item() == final_pred:\n",
        "                    correct_pred[cifar_classes[labels[i].item()]] += 1\n",
        "                total_pred[cifar_classes[labels[i].item()]] += 1\n",
        "    cov = str(total) + str(\" out of\") + str(real_total)\n",
        "    to_print = {\"coverage\": cov, \"system accuracy\": 100 * correct_sys / real_total,\n",
        "                \"expert accuracy\": 100 * exp / (exp_total + 0.0002),\n",
        "                \"classifier accuracy\": 100 * correct / (total + 0.0001),\n",
        "                \"alone classifier\": 100 * alone_correct / real_total}\n",
        "    print(to_print)\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(\"Accuracy for class {:5s} is: {:.3f} %\".format(classname,\n",
        "                                                    accuracy))\n",
        "    return to_print\n",
        "def metrics_print_oracle(net_class, expert_fn, expert_k, n_classes, loader):\n",
        "    correct = 0\n",
        "    correct_sys = 0\n",
        "    exp = 0\n",
        "    exp_total = 0\n",
        "    total = 0\n",
        "    real_total = 0\n",
        "    correct_pred = {classname: 0 for classname in cifar_classes}\n",
        "    total_pred = {classname: 0 for classname in cifar_classes}\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels, _, _ ,_ = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs_class = net_class(images)\n",
        "            _, predicted = torch.max(outputs_class.data, 1)\n",
        "            batch_size = outputs_class.size()[0]  # batch_size\n",
        "\n",
        "            exp_prediction = expert_fn(images, labels)\n",
        "            for i in range(0, batch_size):\n",
        "                r = (expert_k >= labels[i].item()) \n",
        "                final_pred = 0\n",
        "                #r = (exp_prediction[i] == labels[i].item()), this has noise\n",
        "                if r == 0:\n",
        "                    total += 1\n",
        "                    prediction = predicted[i]\n",
        "                    if predicted[i] == n_classes:\n",
        "                        max_idx = 0\n",
        "                        for j in range(0, n_classes):\n",
        "                            if outputs_class.data[i][j] >= outputs_class.data[i][max_idx]:\n",
        "                                max_idx = j\n",
        "                        prediction = max_idx\n",
        "                    else:\n",
        "                        prediction = predicted[i]\n",
        "                    final_pred = prediction\n",
        "                    correct += (prediction == labels[i]).item()\n",
        "                    correct_sys += (prediction == labels[i]).item()\n",
        "                if r == 1:\n",
        "                    final_pred = exp_prediction[i]\n",
        "                    exp += (exp_prediction[i] == labels[i].item())\n",
        "                    correct_sys += (exp_prediction[i] == labels[i].item())\n",
        "                    exp_total += 1\n",
        "                real_total += 1\n",
        "                if labels[i].item() == final_pred:\n",
        "                    correct_pred[cifar_classes[labels[i].item()]] += 1\n",
        "                total_pred[cifar_classes[labels[i].item()]] += 1\n",
        "    cov = str(total) + str(\" out of\") + str(real_total)\n",
        "    to_print = {\"coverage\": cov, \"system accuracy\": 100 * correct_sys / real_total,\n",
        "                \"expert accuracy\": 100 * exp / (exp_total + 0.0002),\n",
        "                \"classifier accuracy\": 100 * correct / (total + 0.0001)}\n",
        "    print(to_print)\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(\"Accuracy for class {:5s} is: {:.3f} %\".format(classname,\n",
        "                                                    accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L92TiTGA267d"
      },
      "outputs": [],
      "source": [
        "cifar_classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def metrics_print_classifier(model, data_loader, defer_net = False):\n",
        "    '''\n",
        "    model: model\n",
        "    data_loader: data loader\n",
        "    defer_net: boolean to indicate if model is a deferral module (has n_classes +1 outputs)\n",
        "    '''\n",
        "    # prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in cifar_classes}\n",
        "    total_pred = {classname: 0 for classname in cifar_classes}\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # again no gradients needed\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            images, labels, _, _ ,_ = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predictions = torch.max(outputs.data, 1) # maybe no .data\n",
        "            if defer_net:\n",
        "                predictions_fixed = predictions\n",
        "                for i in range(len(predictions_fixed)):\n",
        "                    if predictions_fixed[i] == 10: #max class\n",
        "                        max_idx = 0\n",
        "                        # get second max\n",
        "                        for j in range(0, 10):\n",
        "                            if outputs.data[i][j] >= outputs.data[i][max_idx]:\n",
        "                                max_idx = j\n",
        "                        prediction = max_idx\n",
        "                        predictions_fixed[i] = prediction\n",
        "            total += labels.size(0)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            # collect the correct predictions for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "                if label == prediction:\n",
        "                    correct_pred[cifar_classes[label]] += 1\n",
        "                total_pred[cifar_classes[label]] += 1\n",
        "\n",
        "    print('Accuracy of the network on the %d test images: %.3f %%' % (len(data_loader),\n",
        "        100 * correct / total))\n",
        "    # print accuracy for each class\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(\"Accuracy for class {:5s} is: {:.3f} %\".format(classname,\n",
        "                                                    accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqf_r99A1OcX"
      },
      "source": [
        "# Initialize expert and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZxCEtfhRAFB"
      },
      "outputs": [],
      "source": [
        "k = 5 # number of classes expert can predict\n",
        "n_dataset = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXfR2kpyzs_5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class synth_expert:\n",
        "    '''\n",
        "    simple class to describe our synthetic expert on CIFAR-10\n",
        "    ----\n",
        "    k: number of classes expert can predict\n",
        "    n_classes: number of classes (10+1 for CIFAR-10)\n",
        "    '''\n",
        "    def __init__(self, k, n_classes):\n",
        "        self.k = k\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def predict(self, input, labels):\n",
        "        batch_size = labels.size()[0]  # batch_size\n",
        "        outs = [0] * batch_size\n",
        "        for i in range(0, batch_size):\n",
        "            if labels[i].item() <= self.k -1: # CHANGE FROM OLD PAPER\n",
        "                outs[i] = labels[i].item()\n",
        "            else:\n",
        "                # change to determinsticly false\n",
        "                prediction_rand = random.randint(0, self.n_classes - 1)\n",
        "                outs[i] = prediction_rand\n",
        "        return outs\n",
        "\n",
        "\n",
        "Expert = synth_expert(k, n_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PwaJBFx2dFA"
      },
      "outputs": [],
      "source": [
        "model = WideResNet(10, n_dataset + 1, 4, dropRate=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Active Learning Prep"
      ],
      "metadata": {
        "id": "uUHnGa-M-GGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# at each point maintain, a dataset full of labeled points, dataset of unlabeled points\n",
        "# initially: random points\n",
        "# train on labaled dataset\n",
        "# compute score on unlabaled data\n",
        "# move top unlabaled points to labeled set \n",
        "# re-train"
      ],
      "metadata": {
        "id": "9TP5wuHT-IWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_data_aug = False\n",
        "n_dataset = 10  # cifar-10\n",
        "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                    std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "if use_data_aug:\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: F.pad(x.unsqueeze(0),\n",
        "                                            (4, 4, 4, 4), mode='reflect').squeeze()),\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomCrop(32),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "else:\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "if n_dataset == 10:\n",
        "    dataset = 'cifar10'\n",
        "elif n_dataset == 100:\n",
        "    dataset = 'cifar100'\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True}\n",
        "\n",
        "\n",
        "train_dataset_all = datasets.__dict__[dataset.upper()]('../data', train=True, download=True,\n",
        "                                                        transform=transform_train)\n",
        "train_size = int(0.90 * len(train_dataset_all))\n",
        "test_size = len(train_dataset_all) - train_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset_all, [train_size, test_size],  generator=torch.Generator().manual_seed(66))\n",
        "#train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "#                                           batch_size=128, shuffle=True, **kwargs)\n",
        "#val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "#                                            batch_size=128, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                 std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "test_dataset = datasets.__dict__[\"cifar10\".upper()]('../data', train=False, transform=transform_test, download=True)\n",
        "#test_loader = torch.utils.data.DataLoader(\n",
        "#    datasets.__dict__[\"cifar100\".upper()]('../data', train=False, transform=transform_test, download=True),\n",
        "#    batch_size=128, shuffle=True, **kwargs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxukz8OwMX7j",
        "outputId": "6311b3da-fde1-4fba-d2f6-4eb45d503154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarExpertDataset(Dataset):\n",
        "    def __init__(self, images, targets, expert_fn, labeled, indices = None):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        self.images = images\n",
        "        self.targets = np.array(targets)\n",
        "        self.expert_fn = expert_fn\n",
        "        self.labeled = np.array(labeled)\n",
        "        self.expert_preds = np.array(expert_fn(None, torch.FloatTensor(targets)))\n",
        "        for i in range(len(self.expert_preds)):\n",
        "            if self.labeled[i] == 0:\n",
        "                self.expert_preds[i] = -1 # not labeled by expert\n",
        "        if indices != None:\n",
        "            self.indices = indices\n",
        "        else:\n",
        "            self.indices = np.array(list(range(len(self.targets))))\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Take the index of item and returns the image, label, expert prediction and index in original dataset\"\"\"\n",
        "        label = self.targets[index]\n",
        "        image = transform_test(self.images[index])\n",
        "        expert_pred = self.expert_preds[index]\n",
        "        indice = self.indices[index]\n",
        "        labeled = self.labeled[index]\n",
        "        return torch.FloatTensor(image), label, expert_pred, indice, labeled\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)"
      ],
      "metadata": {
        "id": "hNzQOWWtC-Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = CifarExpertDataset(np.array(train_dataset.dataset.data)[train_dataset.indices], np.array(train_dataset.dataset.targets)[train_dataset.indices], Expert.predict , [1]*len(train_dataset.indices))\n",
        "dataset_val = CifarExpertDataset(np.array(val_dataset.dataset.data)[val_dataset.indices], np.array(val_dataset.dataset.targets)[val_dataset.indices], Expert.predict , [1]*len(val_dataset.indices))\n",
        "dataset_test = CifarExpertDataset(test_dataset.data , test_dataset.targets, Expert.predict , [1]*len(test_dataset.targets))\n",
        "\n",
        "dataLoaderTrain = DataLoader(dataset=dataset_train, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
        "dataLoaderVal = DataLoader(dataset=dataset_val, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTest = DataLoader(dataset=dataset_test, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)"
      ],
      "metadata": {
        "id": "KWIHchCVWMP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_reject(train_loader, model, optimizer, scheduler, epoch, expert_fn, n_classes, alpha):\n",
        "    \"\"\"Train for one epoch on the training set with deferral\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target, expert, _, _ ) in enumerate(train_loader):\n",
        "        target = target.to(device)\n",
        "        input = input.to(device)\n",
        "        m = expert.to(device)\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "\n",
        "        # get expert  predictions and costs\n",
        "        batch_size = output.size()[0]  # batch_size\n",
        "        m2 = [0] * batch_size\n",
        "        for j in range(0, batch_size):\n",
        "            if m[j].item() == target[j].item():\n",
        "                m[j] = 1\n",
        "                m2[j] = alpha\n",
        "            else:\n",
        "                m[j] = 0\n",
        "                m2[j] = 1\n",
        "        m = torch.tensor(m)\n",
        "        m2 = torch.tensor(m2)\n",
        "        m = m.to(device)\n",
        "        m2 = m2.to(device)\n",
        "        # done getting expert predictions and costs \n",
        "        # compute loss\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = reject_CrossEntropyLoss(output, m, target, m2, n_classes)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                loss=losses, top1=top1))\n",
        "\n",
        "def train_reject_class(train_loader, model, optimizer, scheduler, epoch):\n",
        "    \"\"\"Train for one epoch on the training set without deferral\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target, expert, _, _ ) in enumerate(train_loader):\n",
        "        target = target.to(device)\n",
        "        input = input.to(device)\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "\n",
        "        # compute loss\n",
        "        loss = my_CrossEntropyLoss(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                loss=losses, top1=top1))\n",
        "\n",
        "\n",
        "def validate_reject(val_loader, model, epoch, expert_fn, n_classes):\n",
        "    \"\"\"Perform validation on the validation set with deferral\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target, expert, _ , _ ) in enumerate(val_loader):\n",
        "        target = target.to(device)\n",
        "        input = input.to(device)\n",
        "\n",
        "        # compute output\n",
        "        with torch.no_grad():\n",
        "            output = model(input)\n",
        "        # expert prediction\n",
        "        batch_size = output.size()[0]  # batch_size\n",
        "        m = expert\n",
        "        alpha = 1\n",
        "        m2 = [0] * batch_size\n",
        "        for j in range(0, batch_size):\n",
        "            if m[j] == target[j].item():\n",
        "                m[j] = 1\n",
        "                m2[j] = alpha\n",
        "            else:\n",
        "                m[j] = 0\n",
        "                m2[j] = 1\n",
        "        m = torch.tensor(m)\n",
        "        m2 = torch.tensor(m2)\n",
        "        m = m.to(device)\n",
        "        m2 = m2.to(device)\n",
        "        # compute loss\n",
        "        loss = reject_CrossEntropyLoss(output, m, target, m2, n_classes)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                top1=top1))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f}'.format(top1=top1))\n",
        "\n",
        "    return top1.avg\n"
      ],
      "metadata": {
        "id": "oDcPb90Bc4xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_reject(model, n_dataset, expert_fn, epochs, alpha, train_loader, val_loader):\n",
        "    '''\n",
        "    model: WideResNet model\n",
        "    data_aug: boolean to use data augmentation in training\n",
        "    n_dataset: number of classes\n",
        "    expert_fn: expert model\n",
        "    epochs: number of epochs to train\n",
        "    alpha: alpha parameter in L_{CE}^{\\alpha}\n",
        "    '''\n",
        "    # Data loading code\n",
        "   \n",
        "    # get the number of model parameters\n",
        "    print('Number of model parameters: {}'.format(\n",
        "        sum([p.data.nelement() for p in model.parameters()])))\n",
        "\n",
        "    # for training on multiple GPUs.\n",
        "    # Use CUDA_VISIBLE_DEVICES=0,1 to specify which GPUs to use\n",
        "    # model = torch.nn.DataParallel(model).cuda()\n",
        "    model = model.to(device)\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), 0.001, #0.001\n",
        "    #                            momentum=0.9, nesterov=True,\n",
        "    #                            weight_decay=5e-4)\n",
        "    optimizer = torch.optim.Adadelta(model.parameters(), lr=0.001, rho=0.9, eps=1e-06, weight_decay=5e-4)\n",
        "\n",
        "    # cosine learning rate\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs)\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "        # train for one epoch\n",
        "        train_reject(train_loader, model, optimizer, scheduler, epoch, expert_fn, n_dataset, alpha)\n",
        "        if epoch % 10 == 0:\n",
        "            metrics_print(model, expert_fn, n_dataset, val_loader)\n",
        "\n",
        "\n",
        "def run_reject_class(model, epochs, train_loader, val_loader):\n",
        "    '''\n",
        "    only train classifier\n",
        "    model: WideResNet model\n",
        "    epochs: number of epochs to train\n",
        "    '''\n",
        "    # get the number of model parameters\n",
        "    print('Number of model parameters: {}'.format(\n",
        "        sum([p.data.nelement() for p in model.parameters()])))\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), 0.001, #0.001\n",
        "    #                            momentum=0.9, nesterov=True,\n",
        "    #                            weight_decay=5e-4)\n",
        "    optimizer = torch.optim.Adadelta(model.parameters(), lr=0.1, rho=0.9, eps=1e-06, weight_decay=5e-4)\n",
        "\n",
        "    # cosine learning rate\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs)\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "        # train for one epoch\n",
        "        train_reject_class(train_loader, model, optimizer, scheduler, epoch)\n",
        "        if epoch % 10 == 0:\n",
        "            metrics_print_classifier(model, val_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "uSuMhHTGdGg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run_reject_class(model, 100, dataLoaderTrain, dataLoaderVal)"
      ],
      "metadata": {
        "id": "Usl2MBKbHAxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal Solution"
      ],
      "metadata": {
        "id": "s8bHnx2qbN2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NetSimple(n_dataset + 1, 100, 100, 1000,500).to(device)"
      ],
      "metadata": {
        "id": "OuXS4uU7bRHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_reject(model, 10, Expert.predict, 70,0.5, dataLoaderTrain, dataLoaderVal)\n"
      ],
      "metadata": {
        "id": "290EKr-kbWAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Active Learning"
      ],
      "metadata": {
        "id": "Zot1njxRujwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm 1\n",
        "\n",
        "Example gathering: use uncertainty on expert\n",
        "model training: post-hoc rejector calibrated"
      ],
      "metadata": {
        "id": "aUdzMKjfvSbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = CifarExpertDataset(np.array(train_dataset.dataset.data)[train_dataset.indices], np.array(train_dataset.dataset.targets)[train_dataset.indices], Expert.predict , [1]*len(train_dataset.indices))\n",
        "dataset_val = CifarExpertDataset(np.array(val_dataset.dataset.data)[val_dataset.indices], np.array(val_dataset.dataset.targets)[val_dataset.indices], Expert.predict , [1]*len(val_dataset.indices))\n",
        "dataset_test = CifarExpertDataset(test_dataset.data , test_dataset.targets, Expert.predict , [1]*len(test_dataset.targets))\n",
        "\n",
        "dataLoaderTrain = DataLoader(dataset=dataset_train, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
        "dataLoaderVal = DataLoader(dataset=dataset_val, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTest = DataLoader(dataset=dataset_test, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)"
      ],
      "metadata": {
        "id": "QMGxU96BuA2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = NetSimple(n_dataset + 1, 100, 100, 1000,500).to(device)\n",
        "#model = WideResNet(28, n_dataset + 1, 4, dropRate=0).to(device)\n",
        "run_reject_class(model, 40, dataLoaderTrain, dataLoaderVal)"
      ],
      "metadata": {
        "id": "nBiX8F4sR1i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_print_classifier(model, dataLoaderVal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgsG0usSl_ks",
        "outputId": "1e642db6-43f3-4b8c-912c-91e2b00448d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 40 test images: 78.240 %\n",
            "Accuracy for class plane is: 81.944 %\n",
            "Accuracy for class car   is: 90.349 %\n",
            "Accuracy for class bird  is: 72.600 %\n",
            "Accuracy for class cat   is: 60.417 %\n",
            "Accuracy for class deer  is: 74.849 %\n",
            "Accuracy for class dog   is: 65.028 %\n",
            "Accuracy for class frog  is: 83.976 %\n",
            "Accuracy for class horse is: 80.745 %\n",
            "Accuracy for class ship  is: 87.860 %\n",
            "Accuracy for class truck is: 87.221 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CifarExpertDatasetLinear(Dataset):\n",
        "    def __init__(self, images, targets, expert_fn, labeled,  indices = None, model = None):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        self.images = images\n",
        "        self.targets = np.array(targets)\n",
        "        self.expert_fn = expert_fn\n",
        "        self.model = model\n",
        "        self.labeled = np.array(labeled)\n",
        "        self.expert_preds = np.array(expert_fn(None, torch.FloatTensor(targets)))\n",
        "        for i in range(len(self.expert_preds)):\n",
        "            if self.labeled[i] == 0:\n",
        "                self.expert_preds[i] = -1 # not labeled by expert\n",
        "        if indices != None:\n",
        "            self.indices = indices\n",
        "        else:\n",
        "            self.indices = np.array(list(range(len(self.targets))))\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Take the index of item and returns the image, label, expert prediction and index in original dataset\"\"\"\n",
        "        label = self.targets[index]\n",
        "        image = transform_test(self.images[index])\n",
        "        image_repr = image.to(device)\n",
        "        image_repr = torch.reshape(image_repr, (1,3,32,32)).to(device)\n",
        "        image_repr = self.model.repr(image_repr)\n",
        "        image_repr = image_repr[0]\n",
        "        image_repr = image_repr.to(torch.device('cpu'))\n",
        "        expert_pred = self.expert_preds[index]\n",
        "        indice = self.indices[index]\n",
        "        labeled = self.labeled[index]\n",
        "        return image_repr, label, expert_pred, indice, torch.FloatTensor(image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)"
      ],
      "metadata": {
        "id": "IKclegZBdLAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Active Learning parameters\n",
        "INITIAL_SIZE = 100\n",
        "BATCH_SIZE_AL = 50\n",
        "MAX_ROUNDS = 10\n",
        "EPOCH_TRAIN = 10"
      ],
      "metadata": {
        "id": "DP7UruLjr2mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = CifarExpertDatasetLinear(np.array(train_dataset.dataset.data)[train_dataset.indices], np.array(train_dataset.dataset.targets)[train_dataset.indices], Expert.predict , [1]*len(train_dataset.indices),None, model)\n",
        "dataset_val = CifarExpertDatasetLinear(np.array(val_dataset.dataset.data)[val_dataset.indices], np.array(val_dataset.dataset.targets)[val_dataset.indices], Expert.predict , [1]*len(val_dataset.indices),None, model)\n",
        "dataset_test = CifarExpertDatasetLinear(test_dataset.data , test_dataset.targets, Expert.predict , [1]*len(test_dataset.targets),None,  model)\n",
        "\n",
        "dataLoaderTrain = DataLoader(dataset=dataset_train, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
        "dataLoaderVal = DataLoader(dataset=dataset_val, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTest = DataLoader(dataset=dataset_test, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)"
      ],
      "metadata": {
        "id": "fA9caTGfsA-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_indices = list(range(len(train_dataset.indices)))\n",
        "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
        "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
        "\n",
        "intial_random_set = random.sample(all_indices, INITIAL_SIZE)\n",
        "indices_labeled  = intial_random_set\n",
        "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "\n",
        "\n",
        "\n",
        "dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled, model)\n",
        "dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, model)\n",
        "\n",
        "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)"
      ],
      "metadata": {
        "id": "H1nvi-aKpREl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_expert_confidence(train_loader, model, optimizer, scheduler, epoch):\n",
        "    \"\"\"Train for one epoch on the training set without deferral\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, label, expert_pred, _, _ ) in enumerate(train_loader):\n",
        "        expert_pred = expert_pred.long()\n",
        "        expert_pred = (expert_pred == label) *1\n",
        "        target = expert_pred.to(device)\n",
        "        input = input.to(device)\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "\n",
        "        # compute loss\n",
        "        loss = my_CrossEntropyLoss(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                loss=losses, top1=top1))\n",
        "            \n",
        "\n",
        "\n",
        "def metrics_print_expert(model, data_loader, defer_net = False):\n",
        "    '''\n",
        "    model: model\n",
        "    data_loader: data loader\n",
        "    '''\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # again no gradients needed\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            images, label, expert_pred, _ ,_ = data\n",
        "            expert_pred = expert_pred.long()\n",
        "            expert_pred = (expert_pred == label) *1\n",
        "            images, labels = images.to(device), expert_pred.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predictions = torch.max(outputs.data, 1) # maybe no .data\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the %d test images: %.3f %%' % (total,\n",
        "        100 * correct / total))\n",
        "\n",
        "def run_expert(model, epochs, train_loader, val_loader):\n",
        "    '''\n",
        "    only train classifier\n",
        "    model: WideResNet model\n",
        "    epochs: number of epochs to train\n",
        "    '''\n",
        "    # get the number of model parameters\n",
        "    print('Number of model parameters: {}'.format(\n",
        "        sum([p.data.nelement() for p in model.parameters()])))\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    optimizer = torch.optim.SGD(model.parameters(), 0.001, #0.001\n",
        "                                momentum=0.9, nesterov=True,\n",
        "                                weight_decay=5e-4)\n",
        "\n",
        "    # cosine learning rate\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs)\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "        # train for one epoch\n",
        "        train_expert_confidence(train_loader, model, optimizer, scheduler, epoch)\n",
        "        if epoch % 10 == 0:\n",
        "            metrics_print_expert(model, val_loader)\n",
        "    metrics_print_expert(model, val_loader)"
      ],
      "metadata": {
        "id": "kVY0AgBCwJHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_print_2step(net_mod, net_exp, expert_fn, n_classes, loader):\n",
        "    correct = 0\n",
        "    correct_sys = 0\n",
        "    exp = 0\n",
        "    exp_total = 0\n",
        "    total = 0\n",
        "    real_total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels, expert_preds, _, images_orig = data\n",
        "            images, labels, expert_preds, images_orig = images.to(device), labels.to(device), expert_preds.to(device), images_orig.to(device)\n",
        "            outputs_mod = net_mod(images_orig)\n",
        "            outputs_exp = net_exp(images)\n",
        "            _, predicted = torch.max(outputs_mod.data, 1)\n",
        "            _, predicted_exp = torch.max(outputs_exp.data, 1)\n",
        "            batch_size = outputs_mod.size()[0]  # batch_size\n",
        "            exp_prediction = expert_fn(images, labels)\n",
        "            for i in range(0, batch_size):\n",
        "                r_score =  outputs_mod.data[i][predicted[i].item()].item()\n",
        "                r_score = outputs_exp.data[i][1].item() - r_score\n",
        "                r = 0\n",
        "                if r_score >= 0:\n",
        "                    r = 1\n",
        "                else:\n",
        "                    r = 0\n",
        "                if r == 0:\n",
        "                    total += 1\n",
        "                    correct += (predicted[i] == labels[i]).item()\n",
        "                    correct_sys += (predicted[i] == labels[i]).item()\n",
        "                if r == 1:\n",
        "                    exp += (exp_prediction[i] == labels[i].item())\n",
        "                    correct_sys += (exp_prediction[i] == labels[i].item())\n",
        "                    exp_total += 1\n",
        "                real_total += 1\n",
        "    cov = str(total) + str(\" out of\") + str(real_total)\n",
        "    to_print = {\"coverage\": cov, \"system accuracy\": 100 * correct_sys / real_total,\n",
        "                \"expert accuracy\": 100 * exp / (exp_total + 0.0002),\n",
        "                \"classifier accuracy\": 100 * correct / (total + 0.0001)}\n",
        "    return to_print\n",
        "    print(to_print)"
      ],
      "metadata": {
        "id": "w7ypH-FOOpPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for classifier\n",
        "# train 100 classifiers with random samples of the data\n",
        "# for rejector, just sample 100 \n",
        "# try random\n"
      ],
      "metadata": {
        "id": "3QjZVf77XozP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Intial_random_set = random.sample(all_indices, INITIAL_SIZE)\n"
      ],
      "metadata": {
        "id": "bVQ_t6TGxw8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random selection\n",
        "all_indices = list(range(len(train_dataset.indices)))\n",
        "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
        "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
        "\n",
        "indices_labeled  = Intial_random_set\n",
        "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "\n",
        "dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled, model)\n",
        "dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, model)\n",
        "\n",
        "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "model_expert = Linear_net(50, 2).to(device)\n",
        "run_expert(model_expert, 50, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
        "data_sizes = []\n",
        "error_random = []\n",
        "data_sizes.append(INITIAL_SIZE)\n",
        "metrics_random = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "error_random.append(metrics_random['system accuracy'])\n",
        "for round in range(MAX_ROUNDS):\n",
        "    print(f'\\n \\n Round {round} \\n \\n')\n",
        "    intial_random_set = random.sample(indices_unlabeled, BATCH_SIZE_AL)\n",
        "\n",
        "    indices_labeled  = indices_labeled + intial_random_set \n",
        "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "    dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), None, model)\n",
        "    dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), None, model)\n",
        "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    model_expert = Linear_net(50, 2).to(device)\n",
        "\n",
        "    run_expert(model_expert, 50, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
        "\n",
        "    metrics_random = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "    error_random.append(metrics_random['system accuracy'])\n",
        "    data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)"
      ],
      "metadata": {
        "id": "mj4i8jVNZuWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0015f3-9e1d-4204-cc6c-19f76500aa2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/1]\tTime 0.940 (0.940)\tLoss 3.4730 (3.4730)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 100 test images: 51.000 %\n",
            "Epoch: [1][0/1]\tTime 0.908 (0.908)\tLoss 3.4371 (3.4371)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [2][0/1]\tTime 0.917 (0.917)\tLoss 3.3859 (3.3859)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [3][0/1]\tTime 0.896 (0.896)\tLoss 3.3213 (3.3213)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [4][0/1]\tTime 1.093 (1.093)\tLoss 3.2450 (3.2450)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [5][0/1]\tTime 0.902 (0.902)\tLoss 3.1586 (3.1586)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [6][0/1]\tTime 0.896 (0.896)\tLoss 3.0638 (3.0638)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [7][0/1]\tTime 0.902 (0.902)\tLoss 2.9620 (2.9620)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [8][0/1]\tTime 0.916 (0.916)\tLoss 2.8547 (2.8547)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [9][0/1]\tTime 0.906 (0.906)\tLoss 2.7434 (2.7434)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [10][0/1]\tTime 0.901 (0.901)\tLoss 2.6294 (2.6294)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 100 test images: 51.000 %\n",
            "Epoch: [11][0/1]\tTime 0.910 (0.910)\tLoss 2.5141 (2.5141)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [12][0/1]\tTime 0.885 (0.885)\tLoss 2.3986 (2.3986)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [13][0/1]\tTime 0.903 (0.903)\tLoss 2.2844 (2.2844)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [14][0/1]\tTime 0.903 (0.903)\tLoss 2.1724 (2.1724)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [15][0/1]\tTime 0.911 (0.911)\tLoss 2.0638 (2.0638)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [16][0/1]\tTime 0.902 (0.902)\tLoss 1.9595 (1.9595)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [17][0/1]\tTime 0.947 (0.947)\tLoss 1.8605 (1.8605)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [18][0/1]\tTime 0.888 (0.888)\tLoss 1.7674 (1.7674)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [19][0/1]\tTime 0.892 (0.892)\tLoss 1.6808 (1.6808)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [20][0/1]\tTime 0.905 (0.905)\tLoss 1.6012 (1.6012)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 100 test images: 51.000 %\n",
            "Epoch: [21][0/1]\tTime 0.902 (0.902)\tLoss 1.5288 (1.5288)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [22][0/1]\tTime 0.909 (0.909)\tLoss 1.4636 (1.4636)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [23][0/1]\tTime 0.902 (0.902)\tLoss 1.4056 (1.4056)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [24][0/1]\tTime 0.898 (0.898)\tLoss 1.3545 (1.3545)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [25][0/1]\tTime 0.872 (0.872)\tLoss 1.3098 (1.3098)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [26][0/1]\tTime 0.887 (0.887)\tLoss 1.2711 (1.2711)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [27][0/1]\tTime 0.898 (0.898)\tLoss 1.2380 (1.2380)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [28][0/1]\tTime 0.911 (0.911)\tLoss 1.2097 (1.2097)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [29][0/1]\tTime 0.902 (0.902)\tLoss 1.1858 (1.1858)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [30][0/1]\tTime 0.907 (0.907)\tLoss 1.1657 (1.1657)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 100 test images: 51.000 %\n",
            "Epoch: [31][0/1]\tTime 0.893 (0.893)\tLoss 1.1489 (1.1489)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [32][0/1]\tTime 0.902 (0.902)\tLoss 1.1349 (1.1349)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [33][0/1]\tTime 0.929 (0.929)\tLoss 1.1233 (1.1233)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [34][0/1]\tTime 0.911 (0.911)\tLoss 1.1137 (1.1137)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [35][0/1]\tTime 0.957 (0.957)\tLoss 1.1058 (1.1058)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [36][0/1]\tTime 0.907 (0.907)\tLoss 1.0993 (1.0993)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [37][0/1]\tTime 0.900 (0.900)\tLoss 1.0940 (1.0940)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [38][0/1]\tTime 0.902 (0.902)\tLoss 1.0897 (1.0897)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [39][0/1]\tTime 0.902 (0.902)\tLoss 1.0863 (1.0863)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [40][0/1]\tTime 0.895 (0.895)\tLoss 1.0835 (1.0835)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 100 test images: 51.000 %\n",
            "Epoch: [41][0/1]\tTime 0.909 (0.909)\tLoss 1.0814 (1.0814)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [42][0/1]\tTime 0.931 (0.931)\tLoss 1.0797 (1.0797)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [43][0/1]\tTime 0.901 (0.901)\tLoss 1.0784 (1.0784)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [44][0/1]\tTime 0.893 (0.893)\tLoss 1.0775 (1.0775)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [45][0/1]\tTime 0.896 (0.896)\tLoss 1.0768 (1.0768)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [46][0/1]\tTime 0.901 (0.901)\tLoss 1.0764 (1.0764)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [47][0/1]\tTime 0.895 (0.895)\tLoss 1.0761 (1.0761)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [48][0/1]\tTime 0.890 (0.890)\tLoss 1.0759 (1.0759)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [49][0/1]\tTime 0.892 (0.892)\tLoss 1.0759 (1.0759)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 100 test images: 51.000 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \n",
            " Round 0 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 1.348 (1.348)\tLoss 6.8103 (6.8103)\tPrec@1 49.333 (49.333)\n",
            "Accuracy of the network on the 150 test images: 49.333 %\n",
            "Epoch: [1][0/1]\tTime 1.390 (1.390)\tLoss 6.7706 (6.7706)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [2][0/1]\tTime 1.337 (1.337)\tLoss 6.7140 (6.7140)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [3][0/1]\tTime 1.327 (1.327)\tLoss 6.6424 (6.6424)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [4][0/1]\tTime 1.316 (1.316)\tLoss 6.5576 (6.5576)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [5][0/1]\tTime 1.340 (1.340)\tLoss 6.4612 (6.4612)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [6][0/1]\tTime 1.334 (1.334)\tLoss 6.3549 (6.3549)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [7][0/1]\tTime 1.353 (1.353)\tLoss 6.2400 (6.2400)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [8][0/1]\tTime 1.346 (1.346)\tLoss 6.1181 (6.1181)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [9][0/1]\tTime 1.327 (1.327)\tLoss 5.9905 (5.9905)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [10][0/1]\tTime 1.329 (1.329)\tLoss 5.8583 (5.8583)\tPrec@1 49.333 (49.333)\n",
            "Accuracy of the network on the 150 test images: 49.333 %\n",
            "Epoch: [11][0/1]\tTime 1.359 (1.359)\tLoss 5.7228 (5.7228)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [12][0/1]\tTime 1.356 (1.356)\tLoss 5.5849 (5.5849)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [13][0/1]\tTime 1.389 (1.389)\tLoss 5.4457 (5.4457)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [14][0/1]\tTime 1.351 (1.351)\tLoss 5.3062 (5.3062)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [15][0/1]\tTime 1.336 (1.336)\tLoss 5.1670 (5.1670)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [16][0/1]\tTime 1.339 (1.339)\tLoss 5.0291 (5.0291)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [17][0/1]\tTime 1.377 (1.377)\tLoss 4.8931 (4.8931)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [18][0/1]\tTime 1.343 (1.343)\tLoss 4.7597 (4.7597)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [19][0/1]\tTime 1.347 (1.347)\tLoss 4.6294 (4.6294)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [20][0/1]\tTime 1.333 (1.333)\tLoss 4.5028 (4.5028)\tPrec@1 49.333 (49.333)\n",
            "Accuracy of the network on the 150 test images: 49.333 %\n",
            "Epoch: [21][0/1]\tTime 1.336 (1.336)\tLoss 4.3802 (4.3802)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [22][0/1]\tTime 1.337 (1.337)\tLoss 4.2622 (4.2622)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [23][0/1]\tTime 1.327 (1.327)\tLoss 4.1491 (4.1491)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [24][0/1]\tTime 1.402 (1.402)\tLoss 4.0411 (4.0411)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [25][0/1]\tTime 1.345 (1.345)\tLoss 3.9385 (3.9385)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [26][0/1]\tTime 1.332 (1.332)\tLoss 3.8415 (3.8415)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [27][0/1]\tTime 1.341 (1.341)\tLoss 3.7502 (3.7502)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [28][0/1]\tTime 1.341 (1.341)\tLoss 3.6647 (3.6647)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [29][0/1]\tTime 1.336 (1.336)\tLoss 3.5851 (3.5851)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [30][0/1]\tTime 1.309 (1.309)\tLoss 3.5114 (3.5114)\tPrec@1 49.333 (49.333)\n",
            "Accuracy of the network on the 150 test images: 49.333 %\n",
            "Epoch: [31][0/1]\tTime 1.328 (1.328)\tLoss 3.4435 (3.4435)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [32][0/1]\tTime 1.335 (1.335)\tLoss 3.3813 (3.3813)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [33][0/1]\tTime 1.332 (1.332)\tLoss 3.3249 (3.3249)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [34][0/1]\tTime 1.328 (1.328)\tLoss 3.2739 (3.2739)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [35][0/1]\tTime 1.396 (1.396)\tLoss 3.2282 (3.2282)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [36][0/1]\tTime 1.335 (1.335)\tLoss 3.1877 (3.1877)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [37][0/1]\tTime 1.328 (1.328)\tLoss 3.1521 (3.1521)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [38][0/1]\tTime 1.327 (1.327)\tLoss 3.1211 (3.1211)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [39][0/1]\tTime 1.331 (1.331)\tLoss 3.0945 (3.0945)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [40][0/1]\tTime 1.341 (1.341)\tLoss 3.0720 (3.0720)\tPrec@1 49.333 (49.333)\n",
            "Accuracy of the network on the 150 test images: 49.333 %\n",
            "Epoch: [41][0/1]\tTime 1.326 (1.326)\tLoss 3.0533 (3.0533)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [42][0/1]\tTime 1.331 (1.331)\tLoss 3.0381 (3.0381)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [43][0/1]\tTime 1.348 (1.348)\tLoss 3.0260 (3.0260)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [44][0/1]\tTime 1.324 (1.324)\tLoss 3.0167 (3.0167)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [45][0/1]\tTime 1.342 (1.342)\tLoss 3.0098 (3.0098)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [46][0/1]\tTime 1.400 (1.400)\tLoss 3.0050 (3.0050)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [47][0/1]\tTime 1.339 (1.339)\tLoss 3.0019 (3.0019)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [48][0/1]\tTime 1.334 (1.334)\tLoss 3.0002 (3.0002)\tPrec@1 49.333 (49.333)\n",
            "Epoch: [49][0/1]\tTime 1.357 (1.357)\tLoss 2.9994 (2.9994)\tPrec@1 49.333 (49.333)\n",
            "Accuracy of the network on the 150 test images: 49.333 %\n",
            "\n",
            " \n",
            " Round 1 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 1.799 (1.799)\tLoss 2.7937 (2.7937)\tPrec@1 49.000 (49.000)\n",
            "Accuracy of the network on the 200 test images: 49.000 %\n",
            "Epoch: [1][0/1]\tTime 1.780 (1.780)\tLoss 2.7570 (2.7570)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [2][0/1]\tTime 1.792 (1.792)\tLoss 2.7049 (2.7049)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [3][0/1]\tTime 1.800 (1.800)\tLoss 2.6395 (2.6395)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [4][0/1]\tTime 1.790 (1.790)\tLoss 2.5627 (2.5627)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [5][0/1]\tTime 1.824 (1.824)\tLoss 2.4763 (2.4763)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [6][0/1]\tTime 1.761 (1.761)\tLoss 2.3824 (2.3824)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [7][0/1]\tTime 1.785 (1.785)\tLoss 2.2827 (2.2827)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [8][0/1]\tTime 1.789 (1.789)\tLoss 2.1790 (2.1790)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [9][0/1]\tTime 1.771 (1.771)\tLoss 2.0733 (2.0733)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [10][0/1]\tTime 1.764 (1.764)\tLoss 1.9672 (1.9672)\tPrec@1 49.000 (49.000)\n",
            "Accuracy of the network on the 200 test images: 49.000 %\n",
            "Epoch: [11][0/1]\tTime 1.773 (1.773)\tLoss 1.8624 (1.8624)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [12][0/1]\tTime 1.787 (1.787)\tLoss 1.7605 (1.7605)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [13][0/1]\tTime 1.787 (1.787)\tLoss 1.6630 (1.6630)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [14][0/1]\tTime 1.858 (1.858)\tLoss 1.5710 (1.5710)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [15][0/1]\tTime 1.771 (1.771)\tLoss 1.4858 (1.4858)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [16][0/1]\tTime 1.773 (1.773)\tLoss 1.4080 (1.4080)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [17][0/1]\tTime 1.789 (1.789)\tLoss 1.3383 (1.3383)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [18][0/1]\tTime 1.770 (1.770)\tLoss 1.2767 (1.2767)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [19][0/1]\tTime 1.773 (1.773)\tLoss 1.2233 (1.2233)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [20][0/1]\tTime 1.799 (1.799)\tLoss 1.1777 (1.1777)\tPrec@1 49.000 (49.000)\n",
            "Accuracy of the network on the 200 test images: 49.000 %\n",
            "Epoch: [21][0/1]\tTime 1.777 (1.777)\tLoss 1.1394 (1.1394)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [22][0/1]\tTime 1.832 (1.832)\tLoss 1.1078 (1.1078)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [23][0/1]\tTime 1.785 (1.785)\tLoss 1.0820 (1.0820)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [24][0/1]\tTime 1.781 (1.781)\tLoss 1.0612 (1.0612)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [25][0/1]\tTime 1.798 (1.798)\tLoss 1.0447 (1.0447)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [26][0/1]\tTime 1.786 (1.786)\tLoss 1.0318 (1.0318)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [27][0/1]\tTime 1.778 (1.778)\tLoss 1.0218 (1.0218)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [28][0/1]\tTime 1.813 (1.813)\tLoss 1.0141 (1.0141)\tPrec@1 49.500 (49.500)\n",
            "Epoch: [29][0/1]\tTime 1.774 (1.774)\tLoss 1.0082 (1.0082)\tPrec@1 49.000 (49.000)\n",
            "Epoch: [30][0/1]\tTime 1.830 (1.830)\tLoss 1.0038 (1.0038)\tPrec@1 50.000 (50.000)\n",
            "Accuracy of the network on the 200 test images: 51.500 %\n",
            "Epoch: [31][0/1]\tTime 1.805 (1.805)\tLoss 1.0004 (1.0004)\tPrec@1 51.500 (51.500)\n",
            "Epoch: [32][0/1]\tTime 1.804 (1.804)\tLoss 0.9979 (0.9979)\tPrec@1 52.500 (52.500)\n",
            "Epoch: [33][0/1]\tTime 1.791 (1.791)\tLoss 0.9960 (0.9960)\tPrec@1 53.500 (53.500)\n",
            "Epoch: [34][0/1]\tTime 1.786 (1.786)\tLoss 0.9946 (0.9946)\tPrec@1 55.500 (55.500)\n",
            "Epoch: [35][0/1]\tTime 1.760 (1.760)\tLoss 0.9936 (0.9936)\tPrec@1 56.000 (56.000)\n",
            "Epoch: [36][0/1]\tTime 1.772 (1.772)\tLoss 0.9928 (0.9928)\tPrec@1 55.500 (55.500)\n",
            "Epoch: [37][0/1]\tTime 1.773 (1.773)\tLoss 0.9922 (0.9922)\tPrec@1 55.000 (55.000)\n",
            "Epoch: [38][0/1]\tTime 1.817 (1.817)\tLoss 0.9918 (0.9918)\tPrec@1 55.000 (55.000)\n",
            "Epoch: [39][0/1]\tTime 1.757 (1.757)\tLoss 0.9915 (0.9915)\tPrec@1 53.000 (53.000)\n",
            "Epoch: [40][0/1]\tTime 1.770 (1.770)\tLoss 0.9913 (0.9913)\tPrec@1 53.000 (53.000)\n",
            "Accuracy of the network on the 200 test images: 53.000 %\n",
            "Epoch: [41][0/1]\tTime 1.769 (1.769)\tLoss 0.9911 (0.9911)\tPrec@1 53.000 (53.000)\n",
            "Epoch: [42][0/1]\tTime 1.756 (1.756)\tLoss 0.9910 (0.9910)\tPrec@1 53.000 (53.000)\n",
            "Epoch: [43][0/1]\tTime 1.778 (1.778)\tLoss 0.9909 (0.9909)\tPrec@1 52.000 (52.000)\n",
            "Epoch: [44][0/1]\tTime 1.759 (1.759)\tLoss 0.9908 (0.9908)\tPrec@1 52.500 (52.500)\n",
            "Epoch: [45][0/1]\tTime 1.791 (1.791)\tLoss 0.9908 (0.9908)\tPrec@1 53.000 (53.000)\n",
            "Epoch: [46][0/1]\tTime 1.850 (1.850)\tLoss 0.9907 (0.9907)\tPrec@1 53.500 (53.500)\n",
            "Epoch: [47][0/1]\tTime 1.768 (1.768)\tLoss 0.9907 (0.9907)\tPrec@1 53.500 (53.500)\n",
            "Epoch: [48][0/1]\tTime 1.771 (1.771)\tLoss 0.9907 (0.9907)\tPrec@1 53.500 (53.500)\n",
            "Epoch: [49][0/1]\tTime 1.815 (1.815)\tLoss 0.9907 (0.9907)\tPrec@1 53.500 (53.500)\n",
            "Accuracy of the network on the 200 test images: 53.500 %\n",
            "\n",
            " \n",
            " Round 2 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 2.270 (2.270)\tLoss 8.2337 (8.2337)\tPrec@1 46.800 (46.800)\n",
            "Accuracy of the network on the 250 test images: 46.800 %\n",
            "Epoch: [1][0/1]\tTime 2.198 (2.198)\tLoss 8.1899 (8.1899)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [2][0/1]\tTime 2.226 (2.226)\tLoss 8.1275 (8.1275)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [3][0/1]\tTime 2.220 (2.220)\tLoss 8.0486 (8.0486)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [4][0/1]\tTime 2.287 (2.287)\tLoss 7.9550 (7.9550)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [5][0/1]\tTime 2.230 (2.230)\tLoss 7.8488 (7.8488)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [6][0/1]\tTime 2.225 (2.225)\tLoss 7.7315 (7.7315)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [7][0/1]\tTime 2.230 (2.230)\tLoss 7.6048 (7.6048)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [8][0/1]\tTime 2.228 (2.228)\tLoss 7.4704 (7.4704)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [9][0/1]\tTime 2.236 (2.236)\tLoss 7.3296 (7.3296)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [10][0/1]\tTime 2.293 (2.293)\tLoss 7.1838 (7.1838)\tPrec@1 46.800 (46.800)\n",
            "Accuracy of the network on the 250 test images: 46.800 %\n",
            "Epoch: [11][0/1]\tTime 2.226 (2.226)\tLoss 7.0343 (7.0343)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [12][0/1]\tTime 2.219 (2.219)\tLoss 6.8821 (6.8821)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [13][0/1]\tTime 2.218 (2.218)\tLoss 6.7285 (6.7285)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [14][0/1]\tTime 2.235 (2.235)\tLoss 6.5745 (6.5745)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [15][0/1]\tTime 2.217 (2.217)\tLoss 6.4208 (6.4208)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [16][0/1]\tTime 2.264 (2.264)\tLoss 6.2685 (6.2685)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [17][0/1]\tTime 2.280 (2.280)\tLoss 6.1182 (6.1182)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [18][0/1]\tTime 2.234 (2.234)\tLoss 5.9707 (5.9707)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [19][0/1]\tTime 2.217 (2.217)\tLoss 5.8266 (5.8266)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [20][0/1]\tTime 2.226 (2.226)\tLoss 5.6864 (5.6864)\tPrec@1 46.800 (46.800)\n",
            "Accuracy of the network on the 250 test images: 46.800 %\n",
            "Epoch: [21][0/1]\tTime 2.233 (2.233)\tLoss 5.5506 (5.5506)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [22][0/1]\tTime 2.215 (2.215)\tLoss 5.4198 (5.4198)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [23][0/1]\tTime 2.297 (2.297)\tLoss 5.2942 (5.2942)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [24][0/1]\tTime 2.219 (2.219)\tLoss 5.1742 (5.1742)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [25][0/1]\tTime 2.245 (2.245)\tLoss 5.0601 (5.0601)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [26][0/1]\tTime 2.245 (2.245)\tLoss 4.9520 (4.9520)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [27][0/1]\tTime 2.227 (2.227)\tLoss 4.8501 (4.8501)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [28][0/1]\tTime 2.187 (2.187)\tLoss 4.7546 (4.7546)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [29][0/1]\tTime 2.196 (2.196)\tLoss 4.6655 (4.6655)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [30][0/1]\tTime 2.309 (2.309)\tLoss 4.5828 (4.5828)\tPrec@1 46.800 (46.800)\n",
            "Accuracy of the network on the 250 test images: 46.800 %\n",
            "Epoch: [31][0/1]\tTime 2.238 (2.238)\tLoss 4.5065 (4.5065)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [32][0/1]\tTime 2.215 (2.215)\tLoss 4.4366 (4.4366)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [33][0/1]\tTime 2.219 (2.219)\tLoss 4.3729 (4.3729)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [34][0/1]\tTime 2.241 (2.241)\tLoss 4.3152 (4.3152)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [35][0/1]\tTime 2.253 (2.253)\tLoss 4.2636 (4.2636)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [36][0/1]\tTime 2.219 (2.219)\tLoss 4.2176 (4.2176)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [37][0/1]\tTime 2.301 (2.301)\tLoss 4.1771 (4.1771)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [38][0/1]\tTime 2.213 (2.213)\tLoss 4.1418 (4.1418)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [39][0/1]\tTime 2.213 (2.213)\tLoss 4.1115 (4.1115)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [40][0/1]\tTime 2.244 (2.244)\tLoss 4.0858 (4.0858)\tPrec@1 46.800 (46.800)\n",
            "Accuracy of the network on the 250 test images: 46.800 %\n",
            "Epoch: [41][0/1]\tTime 2.250 (2.250)\tLoss 4.0644 (4.0644)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [42][0/1]\tTime 2.248 (2.248)\tLoss 4.0470 (4.0470)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [43][0/1]\tTime 2.285 (2.285)\tLoss 4.0331 (4.0331)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [44][0/1]\tTime 2.283 (2.283)\tLoss 4.0224 (4.0224)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [45][0/1]\tTime 2.210 (2.210)\tLoss 4.0145 (4.0145)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [46][0/1]\tTime 2.237 (2.237)\tLoss 4.0090 (4.0090)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [47][0/1]\tTime 2.240 (2.240)\tLoss 4.0055 (4.0055)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [48][0/1]\tTime 2.227 (2.227)\tLoss 4.0035 (4.0035)\tPrec@1 46.800 (46.800)\n",
            "Epoch: [49][0/1]\tTime 2.238 (2.238)\tLoss 4.0026 (4.0026)\tPrec@1 46.800 (46.800)\n",
            "Accuracy of the network on the 250 test images: 46.800 %\n",
            "\n",
            " \n",
            " Round 3 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 2.771 (2.771)\tLoss 1.5881 (1.5881)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 300 test images: 51.000 %\n",
            "Epoch: [1][0/1]\tTime 2.683 (2.683)\tLoss 1.5671 (1.5671)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [2][0/1]\tTime 2.662 (2.662)\tLoss 1.5379 (1.5379)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [3][0/1]\tTime 2.683 (2.683)\tLoss 1.5020 (1.5020)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [4][0/1]\tTime 2.655 (2.655)\tLoss 1.4611 (1.4611)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [5][0/1]\tTime 2.694 (2.694)\tLoss 1.4168 (1.4168)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [6][0/1]\tTime 2.654 (2.654)\tLoss 1.3707 (1.3707)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [7][0/1]\tTime 2.656 (2.656)\tLoss 1.3243 (1.3243)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [8][0/1]\tTime 2.664 (2.664)\tLoss 1.2787 (1.2787)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [9][0/1]\tTime 2.711 (2.711)\tLoss 1.2353 (1.2353)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [10][0/1]\tTime 2.654 (2.654)\tLoss 1.1949 (1.1949)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 300 test images: 51.000 %\n",
            "Epoch: [11][0/1]\tTime 2.683 (2.683)\tLoss 1.1582 (1.1582)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [12][0/1]\tTime 2.670 (2.670)\tLoss 1.1256 (1.1256)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [13][0/1]\tTime 2.680 (2.680)\tLoss 1.0973 (1.0973)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [14][0/1]\tTime 2.668 (2.668)\tLoss 1.0734 (1.0734)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [15][0/1]\tTime 2.646 (2.646)\tLoss 1.0536 (1.0536)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [16][0/1]\tTime 2.703 (2.703)\tLoss 1.0377 (1.0377)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [17][0/1]\tTime 2.666 (2.666)\tLoss 1.0251 (1.0251)\tPrec@1 51.333 (51.333)\n",
            "Epoch: [18][0/1]\tTime 2.661 (2.661)\tLoss 1.0155 (1.0155)\tPrec@1 50.333 (50.333)\n",
            "Epoch: [19][0/1]\tTime 2.675 (2.675)\tLoss 1.0083 (1.0083)\tPrec@1 50.333 (50.333)\n",
            "Epoch: [20][0/1]\tTime 2.658 (2.658)\tLoss 1.0031 (1.0031)\tPrec@1 52.333 (52.333)\n",
            "Accuracy of the network on the 300 test images: 51.667 %\n",
            "Epoch: [21][0/1]\tTime 2.726 (2.726)\tLoss 0.9995 (0.9995)\tPrec@1 51.667 (51.667)\n",
            "Epoch: [22][0/1]\tTime 2.671 (2.671)\tLoss 0.9972 (0.9972)\tPrec@1 52.333 (52.333)\n",
            "Epoch: [23][0/1]\tTime 2.663 (2.663)\tLoss 0.9957 (0.9957)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [24][0/1]\tTime 2.660 (2.660)\tLoss 0.9949 (0.9949)\tPrec@1 54.667 (54.667)\n",
            "Epoch: [25][0/1]\tTime 2.669 (2.669)\tLoss 0.9945 (0.9945)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [26][0/1]\tTime 2.677 (2.677)\tLoss 0.9945 (0.9945)\tPrec@1 54.333 (54.333)\n",
            "Epoch: [27][0/1]\tTime 2.712 (2.712)\tLoss 0.9946 (0.9946)\tPrec@1 55.333 (55.333)\n",
            "Epoch: [28][0/1]\tTime 2.650 (2.650)\tLoss 0.9948 (0.9948)\tPrec@1 54.333 (54.333)\n",
            "Epoch: [29][0/1]\tTime 2.682 (2.682)\tLoss 0.9950 (0.9950)\tPrec@1 53.667 (53.667)\n",
            "Epoch: [30][0/1]\tTime 2.686 (2.686)\tLoss 0.9953 (0.9953)\tPrec@1 53.667 (53.667)\n",
            "Accuracy of the network on the 300 test images: 54.333 %\n",
            "Epoch: [31][0/1]\tTime 2.652 (2.652)\tLoss 0.9955 (0.9955)\tPrec@1 54.333 (54.333)\n",
            "Epoch: [32][0/1]\tTime 2.789 (2.789)\tLoss 0.9957 (0.9957)\tPrec@1 53.000 (53.000)\n",
            "Epoch: [33][0/1]\tTime 2.692 (2.692)\tLoss 0.9958 (0.9958)\tPrec@1 52.667 (52.667)\n",
            "Epoch: [34][0/1]\tTime 2.686 (2.686)\tLoss 0.9960 (0.9960)\tPrec@1 53.000 (53.000)\n",
            "Epoch: [35][0/1]\tTime 2.669 (2.669)\tLoss 0.9961 (0.9961)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [36][0/1]\tTime 2.684 (2.684)\tLoss 0.9961 (0.9961)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [37][0/1]\tTime 2.677 (2.677)\tLoss 0.9962 (0.9962)\tPrec@1 53.667 (53.667)\n",
            "Epoch: [38][0/1]\tTime 2.730 (2.730)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [39][0/1]\tTime 2.661 (2.661)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [40][0/1]\tTime 2.687 (2.687)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Accuracy of the network on the 300 test images: 53.333 %\n",
            "Epoch: [41][0/1]\tTime 2.689 (2.689)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [42][0/1]\tTime 2.692 (2.692)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [43][0/1]\tTime 2.738 (2.738)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [44][0/1]\tTime 2.729 (2.729)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [45][0/1]\tTime 2.675 (2.675)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [46][0/1]\tTime 2.701 (2.701)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [47][0/1]\tTime 2.671 (2.671)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [48][0/1]\tTime 2.659 (2.659)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Epoch: [49][0/1]\tTime 2.741 (2.741)\tLoss 0.9962 (0.9962)\tPrec@1 53.333 (53.333)\n",
            "Accuracy of the network on the 300 test images: 53.333 %\n",
            "\n",
            " \n",
            " Round 4 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 3.130 (3.130)\tLoss 2.9785 (2.9785)\tPrec@1 47.143 (47.143)\n",
            "Accuracy of the network on the 350 test images: 47.143 %\n",
            "Epoch: [1][0/1]\tTime 3.104 (3.104)\tLoss 2.9387 (2.9387)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [2][0/1]\tTime 3.146 (3.146)\tLoss 2.8822 (2.8822)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [3][0/1]\tTime 3.162 (3.162)\tLoss 2.8112 (2.8112)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [4][0/1]\tTime 3.133 (3.133)\tLoss 2.7278 (2.7278)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [5][0/1]\tTime 3.133 (3.133)\tLoss 2.6340 (2.6340)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [6][0/1]\tTime 3.125 (3.125)\tLoss 2.5318 (2.5318)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [7][0/1]\tTime 3.146 (3.146)\tLoss 2.4232 (2.4232)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [8][0/1]\tTime 3.171 (3.171)\tLoss 2.3103 (2.3103)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [9][0/1]\tTime 3.137 (3.137)\tLoss 2.1949 (2.1949)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [10][0/1]\tTime 3.134 (3.134)\tLoss 2.0789 (2.0789)\tPrec@1 47.143 (47.143)\n",
            "Accuracy of the network on the 350 test images: 47.143 %\n",
            "Epoch: [11][0/1]\tTime 3.094 (3.094)\tLoss 1.9643 (1.9643)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [12][0/1]\tTime 3.181 (3.181)\tLoss 1.8526 (1.8526)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [13][0/1]\tTime 3.072 (3.072)\tLoss 1.7456 (1.7456)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [14][0/1]\tTime 3.124 (3.124)\tLoss 1.6447 (1.6447)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [15][0/1]\tTime 3.085 (3.085)\tLoss 1.5510 (1.5510)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [16][0/1]\tTime 3.086 (3.086)\tLoss 1.4655 (1.4655)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [17][0/1]\tTime 3.193 (3.193)\tLoss 1.3888 (1.3888)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [18][0/1]\tTime 3.137 (3.137)\tLoss 1.3212 (1.3212)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [19][0/1]\tTime 3.089 (3.089)\tLoss 1.2625 (1.2625)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [20][0/1]\tTime 3.108 (3.108)\tLoss 1.2125 (1.2125)\tPrec@1 47.143 (47.143)\n",
            "Accuracy of the network on the 350 test images: 47.143 %\n",
            "Epoch: [21][0/1]\tTime 3.120 (3.120)\tLoss 1.1706 (1.1706)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [22][0/1]\tTime 3.156 (3.156)\tLoss 1.1361 (1.1361)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [23][0/1]\tTime 3.112 (3.112)\tLoss 1.1080 (1.1080)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [24][0/1]\tTime 3.130 (3.130)\tLoss 1.0854 (1.0854)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [25][0/1]\tTime 3.103 (3.103)\tLoss 1.0676 (1.0676)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [26][0/1]\tTime 3.212 (3.212)\tLoss 1.0537 (1.0537)\tPrec@1 47.429 (47.429)\n",
            "Epoch: [27][0/1]\tTime 3.137 (3.137)\tLoss 1.0429 (1.0429)\tPrec@1 46.571 (46.571)\n",
            "Epoch: [28][0/1]\tTime 3.112 (3.112)\tLoss 1.0347 (1.0347)\tPrec@1 46.286 (46.286)\n",
            "Epoch: [29][0/1]\tTime 3.102 (3.102)\tLoss 1.0284 (1.0284)\tPrec@1 45.429 (45.429)\n",
            "Epoch: [30][0/1]\tTime 3.097 (3.097)\tLoss 1.0237 (1.0237)\tPrec@1 45.714 (45.714)\n",
            "Accuracy of the network on the 350 test images: 44.857 %\n",
            "Epoch: [31][0/1]\tTime 3.146 (3.146)\tLoss 1.0202 (1.0202)\tPrec@1 44.857 (44.857)\n",
            "Epoch: [32][0/1]\tTime 3.134 (3.134)\tLoss 1.0176 (1.0176)\tPrec@1 45.714 (45.714)\n",
            "Epoch: [33][0/1]\tTime 3.136 (3.136)\tLoss 1.0156 (1.0156)\tPrec@1 45.714 (45.714)\n",
            "Epoch: [34][0/1]\tTime 3.141 (3.141)\tLoss 1.0142 (1.0142)\tPrec@1 46.571 (46.571)\n",
            "Epoch: [35][0/1]\tTime 3.160 (3.160)\tLoss 1.0131 (1.0131)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [36][0/1]\tTime 3.083 (3.083)\tLoss 1.0123 (1.0123)\tPrec@1 46.286 (46.286)\n",
            "Epoch: [37][0/1]\tTime 3.146 (3.146)\tLoss 1.0117 (1.0117)\tPrec@1 47.143 (47.143)\n",
            "Epoch: [38][0/1]\tTime 3.105 (3.105)\tLoss 1.0113 (1.0113)\tPrec@1 47.714 (47.714)\n",
            "Epoch: [39][0/1]\tTime 3.121 (3.121)\tLoss 1.0110 (1.0110)\tPrec@1 48.571 (48.571)\n",
            "Epoch: [40][0/1]\tTime 3.153 (3.153)\tLoss 1.0107 (1.0107)\tPrec@1 48.571 (48.571)\n",
            "Accuracy of the network on the 350 test images: 48.000 %\n",
            "Epoch: [41][0/1]\tTime 3.107 (3.107)\tLoss 1.0106 (1.0106)\tPrec@1 48.000 (48.000)\n",
            "Epoch: [42][0/1]\tTime 3.117 (3.117)\tLoss 1.0104 (1.0104)\tPrec@1 47.429 (47.429)\n",
            "Epoch: [43][0/1]\tTime 3.094 (3.094)\tLoss 1.0103 (1.0103)\tPrec@1 46.571 (46.571)\n",
            "Epoch: [44][0/1]\tTime 3.129 (3.129)\tLoss 1.0103 (1.0103)\tPrec@1 46.571 (46.571)\n",
            "Epoch: [45][0/1]\tTime 3.121 (3.121)\tLoss 1.0102 (1.0102)\tPrec@1 46.571 (46.571)\n",
            "Epoch: [46][0/1]\tTime 3.091 (3.091)\tLoss 1.0102 (1.0102)\tPrec@1 46.286 (46.286)\n",
            "Epoch: [47][0/1]\tTime 3.128 (3.128)\tLoss 1.0102 (1.0102)\tPrec@1 46.571 (46.571)\n",
            "Epoch: [48][0/1]\tTime 3.177 (3.177)\tLoss 1.0102 (1.0102)\tPrec@1 46.571 (46.571)\n",
            "Epoch: [49][0/1]\tTime 3.155 (3.155)\tLoss 1.0102 (1.0102)\tPrec@1 46.571 (46.571)\n",
            "Accuracy of the network on the 350 test images: 46.857 %\n",
            "\n",
            " \n",
            " Round 5 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 3.642 (3.642)\tLoss 2.9575 (2.9575)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 400 test images: 54.000 %\n",
            "Epoch: [1][0/1]\tTime 3.572 (3.572)\tLoss 2.9265 (2.9265)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [2][0/1]\tTime 3.578 (3.578)\tLoss 2.8823 (2.8823)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [3][0/1]\tTime 3.617 (3.617)\tLoss 2.8267 (2.8267)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [4][0/1]\tTime 3.582 (3.582)\tLoss 2.7611 (2.7611)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [5][0/1]\tTime 3.549 (3.549)\tLoss 2.6869 (2.6869)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [6][0/1]\tTime 3.576 (3.576)\tLoss 2.6057 (2.6057)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [7][0/1]\tTime 3.640 (3.640)\tLoss 2.5187 (2.5187)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [8][0/1]\tTime 3.606 (3.606)\tLoss 2.4274 (2.4274)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [9][0/1]\tTime 3.573 (3.573)\tLoss 2.3330 (2.3330)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [10][0/1]\tTime 3.580 (3.580)\tLoss 2.2367 (2.2367)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 400 test images: 54.000 %\n",
            "Epoch: [11][0/1]\tTime 3.645 (3.645)\tLoss 2.1398 (2.1398)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [12][0/1]\tTime 3.590 (3.590)\tLoss 2.0434 (2.0434)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [13][0/1]\tTime 3.562 (3.562)\tLoss 1.9486 (1.9486)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [14][0/1]\tTime 3.579 (3.579)\tLoss 1.8563 (1.8563)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [15][0/1]\tTime 3.643 (3.643)\tLoss 1.7676 (1.7676)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [16][0/1]\tTime 3.596 (3.596)\tLoss 1.6832 (1.6832)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [17][0/1]\tTime 3.585 (3.585)\tLoss 1.6038 (1.6038)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [18][0/1]\tTime 3.585 (3.585)\tLoss 1.5300 (1.5300)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [19][0/1]\tTime 3.624 (3.624)\tLoss 1.4622 (1.4622)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [20][0/1]\tTime 3.602 (3.602)\tLoss 1.4005 (1.4005)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 400 test images: 54.000 %\n",
            "Epoch: [21][0/1]\tTime 3.614 (3.614)\tLoss 1.3450 (1.3450)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [22][0/1]\tTime 3.622 (3.622)\tLoss 1.2958 (1.2958)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [23][0/1]\tTime 3.636 (3.636)\tLoss 1.2524 (1.2524)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [24][0/1]\tTime 3.571 (3.571)\tLoss 1.2147 (1.2147)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [25][0/1]\tTime 3.621 (3.621)\tLoss 1.1821 (1.1821)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [26][0/1]\tTime 3.556 (3.556)\tLoss 1.1543 (1.1543)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [27][0/1]\tTime 3.639 (3.639)\tLoss 1.1307 (1.1307)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [28][0/1]\tTime 3.586 (3.586)\tLoss 1.1109 (1.1109)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [29][0/1]\tTime 3.553 (3.553)\tLoss 1.0942 (1.0942)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [30][0/1]\tTime 3.557 (3.557)\tLoss 1.0804 (1.0804)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 400 test images: 54.000 %\n",
            "Epoch: [31][0/1]\tTime 3.629 (3.629)\tLoss 1.0689 (1.0689)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [32][0/1]\tTime 3.538 (3.538)\tLoss 1.0595 (1.0595)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [33][0/1]\tTime 3.620 (3.620)\tLoss 1.0517 (1.0517)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [34][0/1]\tTime 3.594 (3.594)\tLoss 1.0453 (1.0453)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [35][0/1]\tTime 3.622 (3.622)\tLoss 1.0401 (1.0401)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [36][0/1]\tTime 3.528 (3.528)\tLoss 1.0359 (1.0359)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [37][0/1]\tTime 3.546 (3.546)\tLoss 1.0325 (1.0325)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [38][0/1]\tTime 3.570 (3.570)\tLoss 1.0297 (1.0297)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [39][0/1]\tTime 3.606 (3.606)\tLoss 1.0275 (1.0275)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [40][0/1]\tTime 3.572 (3.572)\tLoss 1.0258 (1.0258)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 400 test images: 54.000 %\n",
            "Epoch: [41][0/1]\tTime 3.604 (3.604)\tLoss 1.0244 (1.0244)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [42][0/1]\tTime 3.588 (3.588)\tLoss 1.0233 (1.0233)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [43][0/1]\tTime 3.675 (3.675)\tLoss 1.0225 (1.0225)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [44][0/1]\tTime 3.568 (3.568)\tLoss 1.0219 (1.0219)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [45][0/1]\tTime 3.586 (3.586)\tLoss 1.0215 (1.0215)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [46][0/1]\tTime 3.564 (3.564)\tLoss 1.0213 (1.0213)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [47][0/1]\tTime 3.626 (3.626)\tLoss 1.0211 (1.0211)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [48][0/1]\tTime 3.545 (3.545)\tLoss 1.0210 (1.0210)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [49][0/1]\tTime 3.572 (3.572)\tLoss 1.0209 (1.0209)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 400 test images: 54.000 %\n",
            "\n",
            " \n",
            " Round 6 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 4.061 (4.061)\tLoss 1.0165 (1.0165)\tPrec@1 52.667 (52.667)\n",
            "Accuracy of the network on the 450 test images: 52.444 %\n",
            "Epoch: [1][0/1]\tTime 4.061 (4.061)\tLoss 1.0161 (1.0161)\tPrec@1 52.444 (52.444)\n",
            "Epoch: [2][0/1]\tTime 4.030 (4.030)\tLoss 1.0156 (1.0156)\tPrec@1 52.444 (52.444)\n",
            "Epoch: [3][0/1]\tTime 3.989 (3.989)\tLoss 1.0150 (1.0150)\tPrec@1 52.444 (52.444)\n",
            "Epoch: [4][0/1]\tTime 4.073 (4.073)\tLoss 1.0144 (1.0144)\tPrec@1 52.222 (52.222)\n",
            "Epoch: [5][0/1]\tTime 4.036 (4.036)\tLoss 1.0138 (1.0138)\tPrec@1 52.000 (52.000)\n",
            "Epoch: [6][0/1]\tTime 4.049 (4.049)\tLoss 1.0131 (1.0131)\tPrec@1 51.778 (51.778)\n",
            "Epoch: [7][0/1]\tTime 4.049 (4.049)\tLoss 1.0125 (1.0125)\tPrec@1 52.000 (52.000)\n",
            "Epoch: [8][0/1]\tTime 4.106 (4.106)\tLoss 1.0120 (1.0120)\tPrec@1 51.778 (51.778)\n",
            "Epoch: [9][0/1]\tTime 4.027 (4.027)\tLoss 1.0115 (1.0115)\tPrec@1 51.333 (51.333)\n",
            "Epoch: [10][0/1]\tTime 4.071 (4.071)\tLoss 1.0111 (1.0111)\tPrec@1 50.667 (50.667)\n",
            "Accuracy of the network on the 450 test images: 50.000 %\n",
            "Epoch: [11][0/1]\tTime 4.073 (4.073)\tLoss 1.0107 (1.0107)\tPrec@1 50.000 (50.000)\n",
            "Epoch: [12][0/1]\tTime 4.032 (4.032)\tLoss 1.0104 (1.0104)\tPrec@1 49.778 (49.778)\n",
            "Epoch: [13][0/1]\tTime 3.994 (3.994)\tLoss 1.0102 (1.0102)\tPrec@1 49.111 (49.111)\n",
            "Epoch: [14][0/1]\tTime 4.040 (4.040)\tLoss 1.0100 (1.0100)\tPrec@1 48.667 (48.667)\n",
            "Epoch: [15][0/1]\tTime 4.089 (4.089)\tLoss 1.0098 (1.0098)\tPrec@1 47.333 (47.333)\n",
            "Epoch: [16][0/1]\tTime 4.057 (4.057)\tLoss 1.0097 (1.0097)\tPrec@1 47.556 (47.556)\n",
            "Epoch: [17][0/1]\tTime 4.025 (4.025)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [18][0/1]\tTime 4.043 (4.043)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [19][0/1]\tTime 4.084 (4.084)\tLoss 1.0096 (1.0096)\tPrec@1 47.111 (47.111)\n",
            "Epoch: [20][0/1]\tTime 4.004 (4.004)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Accuracy of the network on the 450 test images: 46.222 %\n",
            "Epoch: [21][0/1]\tTime 4.021 (4.021)\tLoss 1.0096 (1.0096)\tPrec@1 46.222 (46.222)\n",
            "Epoch: [22][0/1]\tTime 4.067 (4.067)\tLoss 1.0096 (1.0096)\tPrec@1 46.222 (46.222)\n",
            "Epoch: [23][0/1]\tTime 4.030 (4.030)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [24][0/1]\tTime 4.044 (4.044)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [25][0/1]\tTime 4.055 (4.055)\tLoss 1.0096 (1.0096)\tPrec@1 46.889 (46.889)\n",
            "Epoch: [26][0/1]\tTime 4.066 (4.066)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [27][0/1]\tTime 4.010 (4.010)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [28][0/1]\tTime 4.030 (4.030)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [29][0/1]\tTime 4.064 (4.064)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [30][0/1]\tTime 4.015 (4.015)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Accuracy of the network on the 450 test images: 46.444 %\n",
            "Epoch: [31][0/1]\tTime 4.025 (4.025)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [32][0/1]\tTime 3.993 (3.993)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [33][0/1]\tTime 4.098 (4.098)\tLoss 1.0096 (1.0096)\tPrec@1 46.222 (46.222)\n",
            "Epoch: [34][0/1]\tTime 4.016 (4.016)\tLoss 1.0096 (1.0096)\tPrec@1 46.222 (46.222)\n",
            "Epoch: [35][0/1]\tTime 4.033 (4.033)\tLoss 1.0096 (1.0096)\tPrec@1 46.222 (46.222)\n",
            "Epoch: [36][0/1]\tTime 4.113 (4.113)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [37][0/1]\tTime 4.018 (4.018)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [38][0/1]\tTime 4.010 (4.010)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [39][0/1]\tTime 4.025 (4.025)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Epoch: [40][0/1]\tTime 4.135 (4.135)\tLoss 1.0096 (1.0096)\tPrec@1 46.444 (46.444)\n",
            "Accuracy of the network on the 450 test images: 46.667 %\n",
            "Epoch: [41][0/1]\tTime 4.043 (4.043)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [42][0/1]\tTime 4.024 (4.024)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [43][0/1]\tTime 4.045 (4.045)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [44][0/1]\tTime 4.116 (4.116)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [45][0/1]\tTime 4.027 (4.027)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [46][0/1]\tTime 4.038 (4.038)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [47][0/1]\tTime 4.075 (4.075)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [48][0/1]\tTime 4.028 (4.028)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Epoch: [49][0/1]\tTime 4.043 (4.043)\tLoss 1.0096 (1.0096)\tPrec@1 46.667 (46.667)\n",
            "Accuracy of the network on the 450 test images: 46.667 %\n",
            "\n",
            " \n",
            " Round 7 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 4.529 (4.529)\tLoss 6.5786 (6.5786)\tPrec@1 54.800 (54.800)\n",
            "Accuracy of the network on the 500 test images: 54.800 %\n",
            "Epoch: [1][0/1]\tTime 4.488 (4.488)\tLoss 6.5470 (6.5470)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [2][0/1]\tTime 4.485 (4.485)\tLoss 6.5021 (6.5021)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [3][0/1]\tTime 4.449 (4.449)\tLoss 6.4451 (6.4451)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [4][0/1]\tTime 4.551 (4.551)\tLoss 6.3777 (6.3777)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [5][0/1]\tTime 4.504 (4.504)\tLoss 6.3011 (6.3011)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [6][0/1]\tTime 4.515 (4.515)\tLoss 6.2165 (6.2165)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [7][0/1]\tTime 4.607 (4.607)\tLoss 6.1253 (6.1253)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [8][0/1]\tTime 4.547 (4.547)\tLoss 6.0283 (6.0283)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [9][0/1]\tTime 4.475 (4.475)\tLoss 5.9268 (5.9268)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [10][0/1]\tTime 4.540 (4.540)\tLoss 5.8217 (5.8217)\tPrec@1 54.800 (54.800)\n",
            "Accuracy of the network on the 500 test images: 54.800 %\n",
            "Epoch: [11][0/1]\tTime 4.491 (4.491)\tLoss 5.7139 (5.7139)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [12][0/1]\tTime 4.475 (4.475)\tLoss 5.6043 (5.6043)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [13][0/1]\tTime 4.518 (4.518)\tLoss 5.4936 (5.4936)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [14][0/1]\tTime 4.447 (4.447)\tLoss 5.3825 (5.3825)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [15][0/1]\tTime 4.475 (4.475)\tLoss 5.2718 (5.2718)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [16][0/1]\tTime 4.461 (4.461)\tLoss 5.1620 (5.1620)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [17][0/1]\tTime 4.545 (4.545)\tLoss 5.0537 (5.0537)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [18][0/1]\tTime 4.487 (4.487)\tLoss 4.9474 (4.9474)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [19][0/1]\tTime 4.508 (4.508)\tLoss 4.8435 (4.8435)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [20][0/1]\tTime 4.517 (4.517)\tLoss 4.7425 (4.7425)\tPrec@1 54.800 (54.800)\n",
            "Accuracy of the network on the 500 test images: 54.800 %\n",
            "Epoch: [21][0/1]\tTime 4.512 (4.512)\tLoss 4.6447 (4.6447)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [22][0/1]\tTime 4.523 (4.523)\tLoss 4.5504 (4.5504)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [23][0/1]\tTime 4.586 (4.586)\tLoss 4.4600 (4.4600)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [24][0/1]\tTime 4.437 (4.437)\tLoss 4.3735 (4.3735)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [25][0/1]\tTime 4.479 (4.479)\tLoss 4.2913 (4.2913)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [26][0/1]\tTime 4.517 (4.517)\tLoss 4.2134 (4.2134)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [27][0/1]\tTime 4.448 (4.448)\tLoss 4.1400 (4.1400)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [28][0/1]\tTime 4.474 (4.474)\tLoss 4.0712 (4.0712)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [29][0/1]\tTime 4.533 (4.533)\tLoss 4.0070 (4.0070)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [30][0/1]\tTime 4.483 (4.483)\tLoss 3.9475 (3.9475)\tPrec@1 54.800 (54.800)\n",
            "Accuracy of the network on the 500 test images: 54.800 %\n",
            "Epoch: [31][0/1]\tTime 4.467 (4.467)\tLoss 3.8925 (3.8925)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [32][0/1]\tTime 4.476 (4.476)\tLoss 3.8421 (3.8421)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [33][0/1]\tTime 4.498 (4.498)\tLoss 3.7962 (3.7962)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [34][0/1]\tTime 4.436 (4.436)\tLoss 3.7546 (3.7546)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [35][0/1]\tTime 4.532 (4.532)\tLoss 3.7174 (3.7174)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [36][0/1]\tTime 4.524 (4.524)\tLoss 3.6843 (3.6843)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [37][0/1]\tTime 4.456 (4.456)\tLoss 3.6551 (3.6551)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [38][0/1]\tTime 4.472 (4.472)\tLoss 3.6296 (3.6296)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [39][0/1]\tTime 4.563 (4.563)\tLoss 3.6078 (3.6078)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [40][0/1]\tTime 4.479 (4.479)\tLoss 3.5892 (3.5892)\tPrec@1 54.800 (54.800)\n",
            "Accuracy of the network on the 500 test images: 54.800 %\n",
            "Epoch: [41][0/1]\tTime 4.466 (4.466)\tLoss 3.5738 (3.5738)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [42][0/1]\tTime 4.617 (4.617)\tLoss 3.5612 (3.5612)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [43][0/1]\tTime 4.491 (4.491)\tLoss 3.5512 (3.5512)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [44][0/1]\tTime 4.512 (4.512)\tLoss 3.5435 (3.5435)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [45][0/1]\tTime 4.584 (4.584)\tLoss 3.5378 (3.5378)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [46][0/1]\tTime 4.441 (4.441)\tLoss 3.5339 (3.5339)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [47][0/1]\tTime 4.458 (4.458)\tLoss 3.5313 (3.5313)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [48][0/1]\tTime 4.475 (4.475)\tLoss 3.5299 (3.5299)\tPrec@1 54.800 (54.800)\n",
            "Epoch: [49][0/1]\tTime 4.504 (4.504)\tLoss 3.5292 (3.5292)\tPrec@1 54.800 (54.800)\n",
            "Accuracy of the network on the 500 test images: 54.800 %\n",
            "\n",
            " \n",
            " Round 8 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 4.960 (4.960)\tLoss 1.2339 (1.2339)\tPrec@1 44.909 (44.909)\n",
            "Accuracy of the network on the 550 test images: 44.909 %\n",
            "Epoch: [1][0/1]\tTime 4.903 (4.903)\tLoss 1.2231 (1.2231)\tPrec@1 44.909 (44.909)\n",
            "Epoch: [2][0/1]\tTime 4.937 (4.937)\tLoss 1.2084 (1.2084)\tPrec@1 44.909 (44.909)\n",
            "Epoch: [3][0/1]\tTime 4.897 (4.897)\tLoss 1.1908 (1.1908)\tPrec@1 44.909 (44.909)\n",
            "Epoch: [4][0/1]\tTime 4.918 (4.918)\tLoss 1.1714 (1.1714)\tPrec@1 44.909 (44.909)\n",
            "Epoch: [5][0/1]\tTime 4.955 (4.955)\tLoss 1.1511 (1.1511)\tPrec@1 44.909 (44.909)\n",
            "Epoch: [6][0/1]\tTime 4.901 (4.901)\tLoss 1.1309 (1.1309)\tPrec@1 44.909 (44.909)\n",
            "Epoch: [7][0/1]\tTime 4.943 (4.943)\tLoss 1.1114 (1.1114)\tPrec@1 44.909 (44.909)\n",
            "Epoch: [8][0/1]\tTime 4.835 (4.835)\tLoss 1.0933 (1.0933)\tPrec@1 45.091 (45.091)\n",
            "Epoch: [9][0/1]\tTime 4.883 (4.883)\tLoss 1.0769 (1.0769)\tPrec@1 44.727 (44.727)\n",
            "Epoch: [10][0/1]\tTime 4.951 (4.951)\tLoss 1.0626 (1.0626)\tPrec@1 44.727 (44.727)\n",
            "Accuracy of the network on the 550 test images: 45.455 %\n",
            "Epoch: [11][0/1]\tTime 4.885 (4.885)\tLoss 1.0503 (1.0503)\tPrec@1 45.455 (45.455)\n",
            "Epoch: [12][0/1]\tTime 4.890 (4.890)\tLoss 1.0401 (1.0401)\tPrec@1 46.000 (46.000)\n",
            "Epoch: [13][0/1]\tTime 4.974 (4.974)\tLoss 1.0319 (1.0319)\tPrec@1 44.000 (44.000)\n",
            "Epoch: [14][0/1]\tTime 4.928 (4.928)\tLoss 1.0254 (1.0254)\tPrec@1 42.909 (42.909)\n",
            "Epoch: [15][0/1]\tTime 4.909 (4.909)\tLoss 1.0204 (1.0204)\tPrec@1 42.545 (42.545)\n",
            "Epoch: [16][0/1]\tTime 4.978 (4.978)\tLoss 1.0168 (1.0168)\tPrec@1 45.636 (45.636)\n",
            "Epoch: [17][0/1]\tTime 4.926 (4.926)\tLoss 1.0142 (1.0142)\tPrec@1 46.364 (46.364)\n",
            "Epoch: [18][0/1]\tTime 4.899 (4.899)\tLoss 1.0125 (1.0125)\tPrec@1 47.636 (47.636)\n",
            "Epoch: [19][0/1]\tTime 4.941 (4.941)\tLoss 1.0114 (1.0114)\tPrec@1 47.455 (47.455)\n",
            "Epoch: [20][0/1]\tTime 4.906 (4.906)\tLoss 1.0108 (1.0108)\tPrec@1 49.818 (49.818)\n",
            "Accuracy of the network on the 550 test images: 51.455 %\n",
            "Epoch: [21][0/1]\tTime 4.871 (4.871)\tLoss 1.0106 (1.0106)\tPrec@1 51.455 (51.455)\n",
            "Epoch: [22][0/1]\tTime 4.889 (4.889)\tLoss 1.0105 (1.0105)\tPrec@1 52.909 (52.909)\n",
            "Epoch: [23][0/1]\tTime 4.873 (4.873)\tLoss 1.0106 (1.0106)\tPrec@1 53.636 (53.636)\n",
            "Epoch: [24][0/1]\tTime 4.876 (4.876)\tLoss 1.0108 (1.0108)\tPrec@1 53.636 (53.636)\n",
            "Epoch: [25][0/1]\tTime 4.984 (4.984)\tLoss 1.0110 (1.0110)\tPrec@1 53.818 (53.818)\n",
            "Epoch: [26][0/1]\tTime 4.891 (4.891)\tLoss 1.0113 (1.0113)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [27][0/1]\tTime 4.904 (4.904)\tLoss 1.0115 (1.0115)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [28][0/1]\tTime 4.963 (4.963)\tLoss 1.0116 (1.0116)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [29][0/1]\tTime 4.861 (4.861)\tLoss 1.0118 (1.0118)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [30][0/1]\tTime 4.891 (4.891)\tLoss 1.0119 (1.0119)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 550 test images: 54.000 %\n",
            "Epoch: [31][0/1]\tTime 5.005 (5.005)\tLoss 1.0120 (1.0120)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [32][0/1]\tTime 4.942 (4.942)\tLoss 1.0120 (1.0120)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [33][0/1]\tTime 4.893 (4.893)\tLoss 1.0121 (1.0121)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [34][0/1]\tTime 4.946 (4.946)\tLoss 1.0121 (1.0121)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [35][0/1]\tTime 4.893 (4.893)\tLoss 1.0121 (1.0121)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [36][0/1]\tTime 4.894 (4.894)\tLoss 1.0121 (1.0121)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [37][0/1]\tTime 4.930 (4.930)\tLoss 1.0121 (1.0121)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [38][0/1]\tTime 4.906 (4.906)\tLoss 1.0121 (1.0121)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [39][0/1]\tTime 4.919 (4.919)\tLoss 1.0120 (1.0120)\tPrec@1 54.182 (54.182)\n",
            "Epoch: [40][0/1]\tTime 4.935 (4.935)\tLoss 1.0120 (1.0120)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 550 test images: 54.000 %\n",
            "Epoch: [41][0/1]\tTime 4.859 (4.859)\tLoss 1.0120 (1.0120)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [42][0/1]\tTime 4.937 (4.937)\tLoss 1.0120 (1.0120)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [43][0/1]\tTime 4.894 (4.894)\tLoss 1.0120 (1.0120)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [44][0/1]\tTime 4.897 (4.897)\tLoss 1.0120 (1.0120)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [45][0/1]\tTime 4.987 (4.987)\tLoss 1.0120 (1.0120)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [46][0/1]\tTime 4.897 (4.897)\tLoss 1.0119 (1.0119)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [47][0/1]\tTime 4.970 (4.970)\tLoss 1.0119 (1.0119)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [48][0/1]\tTime 5.040 (5.040)\tLoss 1.0119 (1.0119)\tPrec@1 54.000 (54.000)\n",
            "Epoch: [49][0/1]\tTime 4.872 (4.872)\tLoss 1.0119 (1.0119)\tPrec@1 54.000 (54.000)\n",
            "Accuracy of the network on the 550 test images: 54.000 %\n",
            "\n",
            " \n",
            " Round 9 \n",
            " \n",
            "\n",
            "Number of model parameters: 102\n",
            "Epoch: [0][0/1]\tTime 5.355 (5.355)\tLoss 4.9898 (4.9898)\tPrec@1 54.167 (54.167)\n",
            "Accuracy of the network on the 600 test images: 54.167 %\n",
            "Epoch: [1][0/1]\tTime 5.426 (5.426)\tLoss 4.9575 (4.9575)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [2][0/1]\tTime 5.294 (5.294)\tLoss 4.9114 (4.9114)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [3][0/1]\tTime 5.358 (5.358)\tLoss 4.8531 (4.8531)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [4][0/1]\tTime 5.430 (5.430)\tLoss 4.7840 (4.7840)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [5][0/1]\tTime 5.339 (5.339)\tLoss 4.7056 (4.7056)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [6][0/1]\tTime 5.447 (5.447)\tLoss 4.6190 (4.6190)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [7][0/1]\tTime 5.399 (5.399)\tLoss 4.5256 (4.5256)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [8][0/1]\tTime 5.384 (5.384)\tLoss 4.4265 (4.4265)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [9][0/1]\tTime 5.389 (5.389)\tLoss 4.3227 (4.3227)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [10][0/1]\tTime 5.281 (5.281)\tLoss 4.2153 (4.2153)\tPrec@1 54.167 (54.167)\n",
            "Accuracy of the network on the 600 test images: 54.167 %\n",
            "Epoch: [11][0/1]\tTime 5.334 (5.334)\tLoss 4.1053 (4.1053)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [12][0/1]\tTime 5.395 (5.395)\tLoss 3.9935 (3.9935)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [13][0/1]\tTime 5.389 (5.389)\tLoss 3.8807 (3.8807)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [14][0/1]\tTime 5.380 (5.380)\tLoss 3.7678 (3.7678)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [15][0/1]\tTime 5.391 (5.391)\tLoss 3.6554 (3.6554)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [16][0/1]\tTime 5.304 (5.304)\tLoss 3.5441 (3.5441)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [17][0/1]\tTime 5.420 (5.420)\tLoss 3.4347 (3.4347)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [18][0/1]\tTime 5.353 (5.353)\tLoss 3.3275 (3.3275)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [19][0/1]\tTime 5.383 (5.383)\tLoss 3.2232 (3.2232)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [20][0/1]\tTime 5.383 (5.383)\tLoss 3.1221 (3.1221)\tPrec@1 54.167 (54.167)\n",
            "Accuracy of the network on the 600 test images: 54.167 %\n",
            "Epoch: [21][0/1]\tTime 5.371 (5.371)\tLoss 3.0246 (3.0246)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [22][0/1]\tTime 5.359 (5.359)\tLoss 2.9311 (2.9311)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [23][0/1]\tTime 5.404 (5.404)\tLoss 2.8418 (2.8418)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [24][0/1]\tTime 5.344 (5.344)\tLoss 2.7570 (2.7570)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [25][0/1]\tTime 5.445 (5.445)\tLoss 2.6768 (2.6768)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [26][0/1]\tTime 5.393 (5.393)\tLoss 2.6015 (2.6015)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [27][0/1]\tTime 5.342 (5.342)\tLoss 2.5310 (2.5310)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [28][0/1]\tTime 5.476 (5.476)\tLoss 2.4654 (2.4654)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [29][0/1]\tTime 5.335 (5.335)\tLoss 2.4048 (2.4048)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [30][0/1]\tTime 5.401 (5.401)\tLoss 2.3490 (2.3490)\tPrec@1 54.167 (54.167)\n",
            "Accuracy of the network on the 600 test images: 54.167 %\n",
            "Epoch: [31][0/1]\tTime 5.378 (5.378)\tLoss 2.2979 (2.2979)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [32][0/1]\tTime 5.370 (5.370)\tLoss 2.2516 (2.2516)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [33][0/1]\tTime 5.511 (5.511)\tLoss 2.2097 (2.2097)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [34][0/1]\tTime 5.447 (5.447)\tLoss 2.1722 (2.1722)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [35][0/1]\tTime 5.455 (5.455)\tLoss 2.1389 (2.1389)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [36][0/1]\tTime 5.558 (5.558)\tLoss 2.1095 (2.1095)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [37][0/1]\tTime 5.470 (5.470)\tLoss 2.0838 (2.0838)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [38][0/1]\tTime 5.455 (5.455)\tLoss 2.0616 (2.0616)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [39][0/1]\tTime 5.483 (5.483)\tLoss 2.0427 (2.0427)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [40][0/1]\tTime 5.435 (5.435)\tLoss 2.0268 (2.0268)\tPrec@1 54.167 (54.167)\n",
            "Accuracy of the network on the 600 test images: 54.167 %\n",
            "Epoch: [41][0/1]\tTime 5.426 (5.426)\tLoss 2.0136 (2.0136)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [42][0/1]\tTime 5.352 (5.352)\tLoss 2.0029 (2.0029)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [43][0/1]\tTime 5.359 (5.359)\tLoss 1.9944 (1.9944)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [44][0/1]\tTime 5.391 (5.391)\tLoss 1.9879 (1.9879)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [45][0/1]\tTime 5.369 (5.369)\tLoss 1.9832 (1.9832)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [46][0/1]\tTime 5.344 (5.344)\tLoss 1.9799 (1.9799)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [47][0/1]\tTime 5.452 (5.452)\tLoss 1.9777 (1.9777)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [48][0/1]\tTime 5.465 (5.465)\tLoss 1.9765 (1.9765)\tPrec@1 54.167 (54.167)\n",
            "Epoch: [49][0/1]\tTime 5.523 (5.523)\tLoss 1.9760 (1.9760)\tPrec@1 54.167 (54.167)\n",
            "Accuracy of the network on the 600 test images: 54.167 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confidence selection\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def get_least_confident_points(model, data_loader, budget):\n",
        "    '''\n",
        "    based on entropy score, can chagnge, but make sure to get max or min accordingly\n",
        "    '''\n",
        "    uncertainty_estimates = []\n",
        "    indices_all = []\n",
        "    for data in data_loader:\n",
        "        images, labels, expert_preds, indices, _ = data\n",
        "        images, labels, expert_preds = images.to(device), labels.to(device), expert_preds.to(device)\n",
        "        outputs = model(images)\n",
        "        batch_size = outputs.size()[0]  \n",
        "        for i in range(0, batch_size):\n",
        "            output_i =  outputs.data[i].cpu().numpy()\n",
        "            entropy_i = entropy(output_i)\n",
        "            #entropy_i = 1 - max(output_i)\n",
        "            uncertainty_estimates.append(entropy_i)\n",
        "            indices_all.append(indices[i].item())\n",
        "    indices_all = np.array(indices_all)\n",
        "    top_budget_indices = np.argsort(uncertainty_estimates)[-budget:]\n",
        "    actual_indices = indices_all[top_budget_indices]\n",
        "    uncertainty_estimates = np.array(uncertainty_estimates)\n",
        "    return actual_indices\n",
        "all_indices = list(range(len(train_dataset.indices)))\n",
        "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
        "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
        "\n",
        "indices_labeled  = Intial_random_set\n",
        "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "\n",
        "dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), None, model)\n",
        "dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), None, model)\n",
        "    \n",
        "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "model_expert = Linear_net(50, 2).to(device)\n",
        "run_expert(model_expert, 10, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
        "data_sizes = []\n",
        "error_confidence = []\n",
        "data_sizes.append(INITIAL_SIZE)\n",
        "metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "error_confidence.append(metrics_confidence['system accuracy'])\n",
        "\n",
        "\n",
        "for round in range(MAX_ROUNDS):\n",
        "    print(f'\\n \\n Round {round} \\n \\n')\n",
        "    indices_confidence = get_least_confident_points(model_expert, dataLoaderTrainUnlabeled, BATCH_SIZE_AL)\n",
        "\n",
        "    indices_labeled  = indices_labeled + intial_random_set \n",
        "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "    dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), None, model)\n",
        "    dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), None, model)\n",
        "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    \n",
        "    model_expert = Linear_net(50, 2).to(device)\n",
        "\n",
        "    run_expert(model_expert, 50, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
        "\n",
        "    metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "    error_confidence.append(metrics_confidence['system accuracy'])\n",
        "    data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)"
      ],
      "metadata": {
        "id": "l7ve6uBzmp5y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "0e539a7d-626c-4dc9-e3f4-a8b569ef227a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0][0/1]\tTime 1.795 (1.795)\tLoss 2.3431 (2.3431)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 100 test images: 51.000 %\n",
            "Epoch: [1][0/1]\tTime 0.934 (0.934)\tLoss 2.3117 (2.3117)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [2][0/1]\tTime 0.922 (0.922)\tLoss 2.2684 (2.2684)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [3][0/1]\tTime 0.924 (0.924)\tLoss 2.2180 (2.2180)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [4][0/1]\tTime 0.921 (0.921)\tLoss 2.1660 (2.1660)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [5][0/1]\tTime 0.921 (0.921)\tLoss 2.1176 (2.1176)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [6][0/1]\tTime 0.925 (0.925)\tLoss 2.0769 (2.0769)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [7][0/1]\tTime 0.919 (0.919)\tLoss 2.0466 (2.0466)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [8][0/1]\tTime 1.008 (1.008)\tLoss 2.0274 (2.0274)\tPrec@1 51.000 (51.000)\n",
            "Epoch: [9][0/1]\tTime 0.949 (0.949)\tLoss 2.0180 (2.0180)\tPrec@1 51.000 (51.000)\n",
            "Accuracy of the network on the 100 test images: 51.000 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \n",
            " Round 0 \n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-79417e20991a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mround\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_ROUNDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n \\n Round {round} \\n \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mindices_confidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_least_confident_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_expert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderTrainUnlabeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE_AL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mindices_labeled\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mindices_labeled\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mintial_random_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-79417e20991a>\u001b[0m in \u001b[0;36mget_least_confident_points\u001b[0;34m(model, data_loader, budget)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0muncertainty_estimates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mindices_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-930bc87a0bfc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mimage_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimage_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_repr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mimage_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mimage_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_repr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mimage_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_repr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-cf9c91d80d79>\u001b[0m in \u001b[0;36mrepr\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-cf9c91d80d79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-cf9c91d80d79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroprate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalInOut\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvShortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.90 GiB total capacity; 14.42 GiB already allocated; 21.75 MiB free; 14.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confidence selection\n",
        "from scipy.stats import entropy\n",
        "\n",
        "\n",
        "def get_least_confident_rejector(model, model_exp, data_loader, budget):\n",
        "    '''\n",
        "    based on entropy score, can chagnge, but make sure to get max or min accordingly\n",
        "    '''\n",
        "    uncertainty_estimates = []\n",
        "    indices_all = []\n",
        "    for data in data_loader:\n",
        "        images, labels, expert_preds, indices, images_orig = data\n",
        "        images, labels, expert_preds, images_orig = images.to(device), labels.to(device), expert_preds.to(device), images_orig.to(device)\n",
        "        outputs_mod = model(images_orig)\n",
        "        outputs_exp = model_exp(images)\n",
        "        batch_size = outputs_mod.size()[0]  \n",
        "        _, predicted = torch.max(outputs_mod.data, 1)\n",
        "        for i in range(0, batch_size):\n",
        "            output_i=  outputs_mod.data[i].cpu().numpy()[predicted[i].item()]\n",
        "            output_exp = outputs_exp.data[i][1].item() \n",
        "            r_score = -abs(output_exp - output_i) #+  entropy(outputs_exp.data[i].cpu().numpy())\n",
        "            #r_score = 1 - output_i\n",
        "            r_actual = (output_exp >= output_i)\n",
        "            error_score = 0\n",
        "            ai_is_correct = (predicted[i].item() != labels[i].item()) * 1.0\n",
        "            error_score = ai_is_correct * (1 - output_i)\n",
        "            #if r_actual == 1:\n",
        "            #    error_score = (expert_preds[i].item() != labels[i].item())*1.0 + entropy(output_exp)\n",
        "            #else:\n",
        "            #    error_score = (predicted[i].item() != labels[i].item())*1.0 + entropy(output_i)\n",
        "            uncertainty_estimates.append(r_score)\n",
        "            indices_all.append(indices[i].item())\n",
        "    uncertainty_estimates = np.array(uncertainty_estimates)\n",
        "    indices_all = np.array(indices_all)\n",
        "    top_budget_indices = np.argsort(uncertainty_estimates)[-budget:]\n",
        "    print(uncertainty_estimates[top_budget_indices])\n",
        "    actual_indices = indices_all[top_budget_indices]\n",
        "    return actual_indices\n",
        "\n",
        "all_indices = list(range(len(train_dataset.indices)))\n",
        "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
        "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
        "\n",
        "indices_labeled  = Intial_random_set\n",
        "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "\n",
        "dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), None, model)\n",
        "dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), None, model)\n",
        "    \n",
        "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "model_expert = Linear_net(100, 2).to(device)\n",
        "run_expert(model_expert, 10, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
        "data_sizes = []\n",
        "error_confidence_rejector = []\n",
        "data_sizes.append(INITIAL_SIZE)\n",
        "metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "error_confidence_rejector.append(metrics_confidence['system accuracy'])\n",
        "\n",
        "\n",
        "for round in range(MAX_ROUNDS):\n",
        "    print(f'\\n \\n Round {round} \\n \\n')\n",
        "    indices_confidence = get_least_confident_rejector(model, model_expert, dataLoaderTrainUnlabeled, BATCH_SIZE_AL)\n",
        "\n",
        "    indices_labeled  = indices_labeled + intial_random_set \n",
        "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "    dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), None, model)\n",
        "    dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), None, model)\n",
        "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    \n",
        "    model_expert = Linear_net(100, 2).to(device)\n",
        "\n",
        "    run_expert(model_expert, 50, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
        "\n",
        "    metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "    error_confidence_rejector.append(metrics_confidence['system accuracy'])\n",
        "    data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)"
      ],
      "metadata": {
        "id": "Q0WiK2eF3DVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confidence of rejector selection\n",
        "from scipy.stats import entropy\n",
        "all_indices = list(range(len(train_dataset.indices)))\n",
        "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
        "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
        "\n",
        "intial_random_set = random.sample(all_indices, INITIAL_SIZE)\n",
        "indices_labeled  = intial_random_set\n",
        "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "\n",
        "dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled)\n",
        "dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled)\n",
        "\n",
        "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "def get_least_confident_rejector(model, model_exp, data_loader, budget):\n",
        "    '''\n",
        "    based on entropy score, can chagnge, but make sure to get max or min accordingly\n",
        "    '''\n",
        "    uncertainty_estimates = []\n",
        "    indices_all = []\n",
        "    for data in data_loader:\n",
        "        images, labels, expert_preds, indices, _ = data\n",
        "        images, labels, expert_preds = images.to(device), labels.to(device), expert_preds.to(device)\n",
        "        outputs_mod = model(images)\n",
        "        outputs_exp = model_exp(images)\n",
        "        batch_size = outputs_mod.size()[0]  \n",
        "        _, predicted = torch.max(outputs_mod.data, 1)\n",
        "        for i in range(0, batch_size):\n",
        "            output_i=  outputs_mod.data[i].cpu().numpy()[predicted[i].item()]\n",
        "            output_exp = outputs_exp.data[i][1].item() \n",
        "            r_score = -abs(output_exp - output_i) #+  entropy(outputs_exp.data[i].cpu().numpy())\n",
        "            #r_score = 1 - output_i\n",
        "            r_actual = (output_exp >= output_i)\n",
        "            error_score = 0\n",
        "            ai_is_correct = (predicted[i].item() != labels[i].item()) * 1.0\n",
        "            error_score = ai_is_correct * (1 - output_i)\n",
        "            #if r_actual == 1:\n",
        "            #    error_score = (expert_preds[i].item() != labels[i].item())*1.0 + entropy(output_exp)\n",
        "            #else:\n",
        "            #    error_score = (predicted[i].item() != labels[i].item())*1.0 + entropy(output_i)\n",
        "            uncertainty_estimates.append(r_score)\n",
        "            indices_all.append(indices[i].item())\n",
        "    uncertainty_estimates = np.array(uncertainty_estimates)\n",
        "    indices_all = np.array(indices_all)\n",
        "    top_budget_indices = np.argsort(uncertainty_estimates)[-budget:]\n",
        "    print(uncertainty_estimates[top_budget_indices])\n",
        "    actual_indices = indices_all[top_budget_indices]\n",
        "    return actual_indices\n",
        "\n",
        "model_expert = NetSimple(2, 100, 100, 1000,500).to(device)\n",
        "run_expert(model_expert, 10, dataLoaderTrainLabeled, dataLoaderTrainLabeled) \n",
        "data_sizes = []\n",
        "error_confidence_rejector = []\n",
        "data_sizes.append(INITIAL_SIZE)\n",
        "metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "error_confidence_rejector.append(metrics_confidence['system accuracy'])\n",
        "for round in range(MAX_ROUNDS):\n",
        "    print(f'\\n \\n Round {round} \\n \\n')\n",
        "    if round % 2 == 1:\n",
        "        indices_confidence = random.sample(indices_unlabeled, BATCH_SIZE_AL)\n",
        "    else:\n",
        "        indices_confidence = get_least_confident_rejector(model, model_expert, dataLoaderTrainUnlabeled, BATCH_SIZE_AL)\n",
        "    indices_labeled  = indices_labeled + list(indices_confidence) \n",
        "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "    dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled))\n",
        "    dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled))\n",
        "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    #model_expert = NetSimple(2, 100, 100, 1000,500).to(device)\n",
        "    run_expert(model_expert, 20, dataLoaderTrainLabeled, dataLoaderVal)\n",
        "\n",
        "    metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "    error_confidence_rejector.append(metrics_confidence['system accuracy'])\n",
        "    data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)"
      ],
      "metadata": {
        "id": "1CVmrPUmoXe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confidence of rejector selection but with L_CE loss\n",
        "\n",
        "all_indices = list(range(len(train_dataset.indices)))\n",
        "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
        "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
        "\n",
        "intial_random_set = random.sample(all_indices, INITIAL_SIZE)\n",
        "indices_labeled  = intial_random_set\n",
        "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "\n",
        "dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled)\n",
        "dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled)\n",
        "\n",
        "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "\n",
        "model_lce = NetSimple(n_dataset + 1, 100, 100, 1000,500).to(device)\n",
        "run_reject_class(model_lce, 10, dataLoaderTrainUnlabeled, dataLoaderVal)\n",
        "\n",
        "#run_reject(model, 10, Expert.predict, 70,0.5, dataLoaderTrain, dataLoaderVal)\n",
        "\n",
        "\n",
        "def get_least_confident_rejector_uncertain(model, data_loader, budget):\n",
        "    '''\n",
        "    based on entropy score, can chagnge, but make sure to get max or min accordingly\n",
        "    '''\n",
        "    uncertainty_estimates = []\n",
        "    indices_all = []\n",
        "    for data in data_loader:\n",
        "        images, labels, expert_preds, indices, _ = data\n",
        "        images, labels, expert_preds = images.to(device), labels.to(device), expert_preds.to(device)\n",
        "        outputs_mod = model(images)\n",
        "        batch_size = outputs_mod.size()[0]  \n",
        "        _, predicted = torch.max(outputs_mod.data, 1)\n",
        "        for i in range(0, batch_size):\n",
        "            output_i=  outputs_mod.data[i].cpu().numpy()[predicted[i].item()]\n",
        "            output_exp = outputs_exp.data[i][1].item()\n",
        "            all_output_exp =  outputs_exp.data[i].cpu().numpy()\n",
        "            entropy_exp = entropy(all_output_exp)\n",
        "            r_score = -abs(output_exp - output_i) + entropy_exp\n",
        "            uncertainty_estimates.append(r_score)\n",
        "            indices_all.append(indices[i].item())\n",
        "    indices_all = np.array(indices_all)\n",
        "    top_budget_indices = np.argsort(uncertainty_estimates)[-budget:]\n",
        "    actual_indices = indices_all[top_budget_indices]\n",
        "    return actual_indices\n",
        "\n",
        "#model_expert = NetSimple(2, 100, 100, 1000,500).to(device)\n",
        "#run_expert(model_expert, 10, dataLoaderTrainLabeled, dataLoaderTrainLabeled) \n",
        "data_sizes = []\n",
        "errors_LCE = []\n",
        "data_sizes.append(INITIAL_SIZE)\n",
        "metrics_confidence = metrics_print(model_lce, Expert.predict, n_dataset, dataLoaderVal)\n",
        "errors_LCE.append(metrics_confidence['system accuracy'])\n",
        "for round in range(MAX_ROUNDS):\n",
        "    print(f'\\n \\n Round {round} \\n \\n')\n",
        "    #indices_confidence = get_least_confident_rejector(model, model_expert, dataLoaderTrainUnlabeled, BATCH_SIZE_AL)\n",
        "    indices_confidence = random.sample(indices_unlabeled, BATCH_SIZE_AL)\n",
        "    indices_labeled  = indices_labeled + list(indices_confidence) \n",
        "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "    dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled))\n",
        "    dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled))\n",
        "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    \n",
        "    #run_expert(model_expert, 20, dataLoaderTrainLabeled, dataLoaderVal)\n",
        "    run_reject(model_lce, 10, Expert.predict, 1, 0.5, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
        "    metrics_confidence = metrics_print(model_lce, Expert.predict, n_dataset, dataLoaderVal)\n",
        "    errors_LCE.append(metrics_confidence['system accuracy'])\n",
        "    data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)"
      ],
      "metadata": {
        "id": "H3Me6cnD7J7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teaching baseline\n",
        "import copy\n",
        "from scipy.stats import entropy\n",
        "all_indices = list(range(len(train_dataset.indices)))\n",
        "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
        "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
        "\n",
        "intial_random_set = random.sample(all_indices, INITIAL_SIZE)\n",
        "indices_labeled  = intial_random_set\n",
        "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
        "\n",
        "dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled)\n",
        "dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled)\n",
        "\n",
        "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "model_expert = NetSimple(2, 100, 100, 1000,500).to(device)\n",
        "run_expert(model_expert, 10, dataLoaderTrainLabeled, dataLoaderTrainLabeled) \n",
        "data_sizes = []\n",
        "errors_teaching = []\n",
        "data_sizes.append(INITIAL_SIZE)\n",
        "metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "errors_teaching.append(metrics_confidence['system accuracy'])\n",
        "RANDOM_SEARCH_SIZE = 30\n",
        "for round in range(MAX_ROUNDS):\n",
        "    print(f'\\n \\n Round {round} \\n \\n')\n",
        "    random_sets = []\n",
        "    best_set_score = 0\n",
        "    best_set = []\n",
        "    saved_expert_model = copy.deepcopy(model_expert.state_dict())\n",
        "    for trial_set in range(RANDOM_SEARCH_SIZE):\n",
        "        model_expert.load_state_dict(saved_expert_model)\n",
        "        random_set = random.sample(indices_unlabeled, BATCH_SIZE_AL)\n",
        "        random_sets.append(random_set)\n",
        "        indices_labeled_trial  = indices_labeled + list(random_set) \n",
        "        indices_unlabeled_trial= list(set(all_indices) - set(indices_labeled))\n",
        "        dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled))\n",
        "        dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled))\n",
        "        dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "        run_expert(model_expert, 20, dataLoaderTrainLabeled, dataLoaderVal)\n",
        "        metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "        error_random_set = metrics_confidence['system accuracy']\n",
        "        if error_random_set >= best_set_score:\n",
        "            best_set_score = error_random_set\n",
        "            best_set = random_set\n",
        "\n",
        "    model_expert.load_state_dict(saved_expert_model)\n",
        "    indices_labeled  = indices_labeled + list(best_set) \n",
        "    indices_unlabeled = list(set(all_indices) - set(indices_labeled))\n",
        "    dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled))\n",
        "    dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled))\n",
        "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
        "    run_expert(model_expert, 20, dataLoaderTrainLabeled, dataLoaderVal)\n",
        "    metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
        "    errors_teaching.append(metrics_confidence['system accuracy'])\n",
        "    data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)"
      ],
      "metadata": {
        "id": "xXQt1d6Yq4cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.rcParams['pdf.fonttype'] = 42\n",
        "matplotlib.rcParams['ps.fonttype'] = 42\n",
        "plt.rc('text', usetex=False)\n",
        "plt.rc('font', family='serif')\n",
        "def get_conf_interval(arr):\n",
        "    alpha_level = 0.4\n",
        "    err  = st.t.interval(alpha_level, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))[1]/2  - st.t.interval(alpha_level, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))[0]/2 \n",
        "    return err"
      ],
      "metadata": {
        "id": "Jk7MhFZdUExS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_sizes2 = data_sizes[:59]\n",
        "#avgs_rand = [np.average([scores_oracle[triall] - scores_lime[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
        "#stds_rand = [np.std([scores_oracle[triall] -scores_lime[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
        "#plt.errorbar(list(range(1,len(teaching_sizes)+1)),  avgs_rand, yerr=stds_rand, label=f'random')\n",
        "plt.errorbar(data_sizes2,  error_random[:59], yerr=[0]*len(data_sizes2), marker = \"+\",  label=f'Random')\n",
        "#plt.errorbar(data_sizes2,  error_confidence[:59], yerr=[0]*len(data_sizes2), marker = \"+\",  label=f'Entropy Sampling')\n",
        "#plt.errorbar(data_sizes,  error_confidence_rejector, yerr=[0]*len(error_confidence_rejector), marker = \"+\",  label=f'Rejector Uncertainty')\n",
        "#plt.errorbar(data_sizes,  errors_LCE, yerr=[0]*len(errors_LCE), marker = \"o\",  label=f'LCE random')\n",
        "#plt.errorbar(data_sizes,  errors_teaching, yerr=[0]*len(error_confidence_rejector), marker = \"o\",  label=f'Teaching')\n",
        "\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.get_xaxis().tick_bottom()    \n",
        "ax.get_yaxis().tick_left()   \n",
        "plt.grid()\n",
        "plt.legend(fontsize='large')\n",
        "plt.legend()\n",
        "plt.ylabel('System Accuracy',  fontsize='x-large')\n",
        "plt.xlabel('Acquired data size', fontsize='x-large')\n",
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 6\n",
        "fig_size[1] = 4\n",
        "#plt.savefig(\"teaching_complexity_cifar10.pdf\", dpi = 1000)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KXSoV9ERUJou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "2129c594-df76-49f6-b699-5cec0e24f19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RCOnmJUI_e99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on unlabeled and retrieve a score for each data point"
      ],
      "metadata": {
        "id": "8692xxBU6YmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "a7Aympk-qwGu",
        "iYllTn0F2iDg",
        "9ll6QD_IrQeD",
        "iqf_r99A1OcX",
        "uUHnGa-M-GGA",
        "s8bHnx2qbN2o"
      ],
      "name": "cifar_active_learning_discrete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
